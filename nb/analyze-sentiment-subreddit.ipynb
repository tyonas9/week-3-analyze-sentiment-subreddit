{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=”false” ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\" id=\"heading\">Sentiment Analysis of Reddit Data using Reddit API</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this live coding session, we leverage the Python Reddit API Wrapper (`PRAW`) to retrieve data from subreddits on [Reddit](https://www.reddit.com), and perform sentiment analysis using [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines) from [HuggingFace ( 🤗 the GitHub of Machine Learning )](https://techcrunch.com/2022/05/09/hugging-face-reaches-2-billion-valuation-to-build-the-github-of-machine-learning/), powered by [transformer](https://arxiv.org/pdf/1706.03762.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the session, you will "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- know how to work with APIs\n",
    "- feel more comfortable navigating thru documentation, even inspecting the source code\n",
    "- understand what a `pipeline` object is in HuggingFace\n",
    "- perform sentiment analysis using `pipeline`\n",
    "- run a python script in command line and get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- At the end of each task, commit* the work into your own remote repo\n",
    "- After completing all three tasks, make sure to push the notebook containing all code blocks and output cells to your remote repo\n",
    "- Submit the link to the notebook in Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\***NEVER** commit a notebook displaying errors unless it is instructed otherwise. However, commit often; recall git ABC = **A**lways **B**e **C**ommitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task I: Instantiate a Reddit API Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first task is to instantiate a Reddit API object using [PRAW](https://praw.readthedocs.io/en/stable/), through which you will retrieve data. PRAW is a wrapper for [Reddit API](https://www.reddit.com/dev/api) that makes interacting with the Reddit API easier unless you are already an expert of [`requests`](https://docs.python-requests.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 0.  Get updates from `FourthBrain/MLE-7`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Under your forked local repo, **fetch** and download new updates from repo `FourthBrain/MLE-7` locally so you can start development. \n",
    "    \n",
    "<details>\n",
    "<summary>If you haven't added `FourthBrain/MLE-7` as a remote repo, click here for instructions:</summary>   \n",
    "You fork repo `FourthBrain/MLE-7` to `yourhandle/MLE-7`, clone it locally, and now you are under directory `MLE-7`. By default, you will see one server name `origin` pointing to your repo:  \n",
    "    \n",
    "```\n",
    "$git remote -v \n",
    "origin  git@github.com:yourhandle/MLE-7.git (fetch)\n",
    "origin  git@github.com:yourhandle/MLE-7.git (push)\n",
    "```\n",
    "\n",
    "Think of fetch = read and push = write. \n",
    "\n",
    "Now add `FourthBrain/MLE-7` as a remote repo\n",
    "\n",
    "```\n",
    "$git remote add fourthbrain git@github.com:FourthBrain/MLE-7.git\n",
    "$git remote -v\n",
    "fourthbrain\tgit@github.com:FourthBrain/MLE-7.git (fetch)\n",
    "fourthbrain\tgit@github.com:FourthBrain/MLE-7.git (push)\n",
    "origin git@github.com:yourhandle/MLE-7.git (fetch)\n",
    "origin git@github.com:yourhandle/MLE-7.git (push)\n",
    "```\n",
    "\n",
    "then before each session starts, run `git fetch fourthbrain` to get updates (why not `git pull`?).\n",
    "\n",
    "check out [Working with Remotes](https://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes) for more explanations.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "conda activate {your_virtual_environment_name}\n",
    "pip install -U transformers praw torch numpy pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2. Create a new app on Reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a new app on Reddit and save secret tokens; refer to [post in medium](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Create a Reddit account if you don't have one, log into your account.\n",
    "- To access the API, we need create an app. Slight updates, on the website, you need to navigate to `preference` > `app`, or click [this link](https://www.reddit.com/prefs/apps) and scroll all the way down. \n",
    "- Click to create a new app, fill in the **name**, choose `script`, fill in  **description** and **redirect url** ( The redirect URI is where the user is sent after they've granted OAuth access to your application; more info [here](and details are in [](https://github.com/reddit-archive/reddit/wiki/OAuth2) for our purpose, you can enter some random url, e.g., www.google.com; ) as shown below.\n",
    "    <img src=\"https://miro.medium.com/max/700/1*lRBvxpIe8J2nZYJ6ucMgHA.png\" width=\"500\"/>\n",
    "- Jolt down `client_id` (left upper corner) and `client_secret` \n",
    "\n",
    "    NOTE: CLIENT_ID refers to 'personal use script\" and CLIENT_SECRET to secret.\n",
    "    <div>\n",
    "    <img src=\"https://miro.medium.com/max/700/1*7cGAKth1PMrEf2sHcQWPoA.png\" width=\"300\"/>\n",
    "    </div>\n",
    "\n",
    "- Create `secrets.py` in the same directory with this notebook, fill in `client_id` and `secret_id` obtained from the last step. We will need to import those constants in the next step.\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = {client_id}\n",
    "    REDDIT_API_CLIENT_SECRET = {secret_id}\n",
    "    REDDIT_API_USER_AGENT = {can_be_any_string_but_bot, e.g., : \"4bai-ml\"}\n",
    "    ```\n",
    "- Add `secrets.py` to your `.gitignore` file if not already done. NEVER push credentials to a repo, private or public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Instantiate a `Reddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you are ready to create a read-only `Reddit` instance. Refer to [documentation](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import redditsecrets\n",
    "\n",
    "# Create a Reddit object which allows us to interact with the Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id = redditsecrets.REDDIT_API_CLIENT_ID,\n",
    "    client_secret = redditsecrets.REDDIT_API_CLIENT_SECRET,\n",
    "    user_agent = redditsecrets.REDDIT_API_USER_AGENT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<praw.reddit.Reddit object at 0x7fcfc432a450>\n"
     ]
    }
   ],
   "source": [
    "print(reddit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "```<praw.reddit.Reddit object at 0x10f8a0ac0>```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Instantiate a `subreddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly, create a `subreddit` object for your favorite subreddit and inspect the object. The expected output you will see ar from `r/machinelearning` unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit('machinelearning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the display name of the subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machinelearning'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    machinelearning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How about its title, is it different from the display name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    Machine Learning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Print out the description of the subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\\n--------\\n+[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\\n--------\\n+[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\\n--------\\n+[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\\n--------\\n+[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit.description[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "    **[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
    "    --------\n",
    "    +[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
    "    --------\n",
    "    +[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
    "    --------\n",
    "    +[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
    "    --------\n",
    "    +[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task II: Parse comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1. Top Posts of All Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Find titles of top 10 posts of **all time** from your favorite subreddit. Refer to [Obtain Submission Instances from a Subreddit Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)) if necessary. Verify if the titles match what you read on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# try run this line, what do you see? press q once you are done\n",
    "?subreddit.top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Project] From books to presentations in 10s with AR + ML\n",
      "[D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
      "[R] First Order Motion Model applied to animate paintings\n",
      "[N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
      "[D] This AI reveals how much time politicians stare at their phone at work\n",
      "[D] Types of Machine Learning Papers\n",
      "[D] The machine learning community has a toxicity problem\n",
      "[Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
      "I made a robot that punishes me if it detects that if I am procrastinating on my assignments [P]\n",
      "[P] Using oil portraits and First Order Model to bring the paintings back to life\n"
     ]
    }
   ],
   "source": [
    "top_10 = subreddit.top(limit=10)\n",
    "\n",
    "for submission in top_10:\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details> <summary>Expected output:</summary>\n",
    "\n",
    "    [Project] From books to presentations in 10s with AR + ML\n",
    "    [D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
    "    [R] First Order Motion Model applied to animate paintings\n",
    "    [N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
    "    [D] This AI reveals how much time politicians stare at their phone at work\n",
    "    [D] Types of Machine Learning Papers\n",
    "    [D] The machine learning community has a toxicity problem\n",
    "    [Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
    "    [P] Using oil portraits and First Order Model to bring the paintings back to life\n",
    "    [D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG)    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2. Top 10 Posts of This Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What are the titles of the top 10 posts of **this week** from your favorite subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30% of Google's Reddit Emotions Dataset is Mislabeled [D]\n",
      "[R] mixed reality future — see the world through artistic lenses — made with NeRF\n",
      "[N] First-Ever Course on Transformers: NOW PUBLIC\n",
      "[D] Why are Corgi dogs so popular in machine learning (especially in the image generation community)?\n",
      "[D] Noam Chomsky on LLMs and discussion of LeCun paper (MLST)\n",
      "[P] Sioyek 1.4 | Academic PDF Viewer\n",
      "[N] Andrej Karpathy is leaving Tesla\n",
      "[R] So someone actually peer-reviewed this and thought \"yeah, looks good\"?\n",
      "[N] BigScience Releases their 176 Billion Parameter Open-access Multilingual Language Model\n",
      "[D] How do you verify the novelty of your research?\n"
     ]
    }
   ],
   "source": [
    "top_10 = subreddit.top(time_filter=\"week\",limit=10)\n",
    "\n",
    "for submission in top_10:\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details><summary>Expected output:</summary>\n",
    "\n",
    "    [N] Ian Goodfellow, Apple’s director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said “I believe strongly that more flexibility would have been the best policy for my team.” He was likely the company’s most cited ML expert.\n",
    "    [R][P] Thin-Plate Spline Motion Model for Image Animation + Gradio Web Demo\n",
    "    [P] I’ve been trying to understand the limits of some of the available machine learning models out there. Built an app that lets you try a mix of CLIP from Open AI + Apple’s version of MobileNet, and more directly on your phone's camera roll.\n",
    "    [R] Meta is releasing a 175B parameter language model\n",
    "    [N] Hugging Face raised $100M at $2B to double down on community, open-source & ethics\n",
    "    [P] T-SNE to view and order your Spotify tracks\n",
    "    [D] : HELP Finding a Book - A book written for Google Engineers about foundational Math to support ML\n",
    "    [R] Scaled up CLIP-like model (~2B) shows 86% Zero-shot on Imagenet\n",
    "    [D] Do you use NLTK or Spacy for text preprocessing?\n",
    "    [D] Democratizing Diffusion Models - LDMs: High-Resolution Image Synthesis with Latent Diffusion Models, a 5-minute paper summary by Casual GAN Papers\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3. Comment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add comments to the code block below to describe what each line of the code does (Refer to [Obtain Comment Instances Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html) when necessary). The code is adapted from [this tutorial](https://praw.readthedocs.io/en/stable/tutorials/comments.html)\n",
    "\n",
    "The purpose is \n",
    "1. to understand what the code is doing \n",
    "2. start to comment your code whenever it is not self-explantory if you have not (others will thank you, YOU will thank you later 😊) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 358 ms, sys: 22.2 ms, total: 381 ms\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# Initialize an empty list to store the top_comments\n",
    "top_comments = []\n",
    "\n",
    "# Looping through the top ten subreddits\n",
    "for submission in subreddit.top(limit=10):\n",
    "    # YOUR COMMENT HERE\n",
    "    # Lopping through the top level comment for the submission \n",
    "    for top_level_comment in submission.comments:\n",
    "        \n",
    "        # The submission contains a number of MoreComments objects that usually appear in comments in the form\n",
    "        # of Button clicks. \n",
    "        #These objects represent the “load more comments”, \n",
    "        #This code ignores these MoreComments and only adds the top_level_comment\n",
    "        \n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # YOUR COMMENT HERE\n",
    "        # Appends the top_level_comment to top_comments list instantiated above\n",
    "        top_comments.append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 4. Inspect Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How many comments did you extract from the last step? Examine a few comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Twitter thread: [https://twitter.com/cyrildiagne/status/1259441154606669824](https://twitter.com/cyrildiagne/status/1259441154606669824)\\n\\nCode: [https://github.com/cyrildiagne/ar-cutpaste/tree/clipboard](https://github.com/cyrildiagne/ar-cutpaste/tree/clipboard)\\n\\nBackground removal is done with U^(2-Net) (Qin et Al, Pattern Recognition 2020): [https://github.com/NathanUA/U-2-Net](https://github.com/NathanUA/U-2-Net)\\n\\n**/!\\\\\\\\ EDIT:** You can now subscribe to a beta program to get early access to the app: [https://arcopypaste.app](https://arcopypaste.app)  !',\n",
       " 'Simple yet very useful. Thank you for sharing the code.',\n",
       " 'The future 🤯',\n",
       " 'Ohh the nightmare of making this into a stable product... Enough to drive you mad just thinking about it',\n",
       " 'Almost guaranteed, Apple will copy your idea in 3, 2, 1....',\n",
       " 'Wtffff. Well that was incredible.',\n",
       " 'Apple can’t wait to steal this and not credit the creators',\n",
       " 'fantastic!',\n",
       " 'Why did the boxes in the diagram turn gray?',\n",
       " 'How does the Algorithm decide what it cuts out from the input pictures? \\n\\nFor example it only cut out the two people in the picture and not the surroundings.\\n\\nAmazing project though!',\n",
       " '#WITCH!  BURN THEM!',\n",
       " 'Any sufficiently advanced technology is indistinguishable from magic.',\n",
       " 'This will be amazing if released, even as a beta. Definitely can see this being very useful',\n",
       " 'Really good work, thanks for sharing!',\n",
       " \"I'm extremely impressed with it cutting dark hair from a brown background. Is that the pixel's camera doing the hard work or is it U^2_Net ? Have you tried it with other phones? How does it deal with feathering? Stunning demo & thanks for posting this.\",\n",
       " 'Super cool',\n",
       " 'Wizardry!',\n",
       " 'Woahhh that is so cool!!! I am wondering the speed wise from the initial snap till pasting it to computer.\\n\\nIf we could get it done >1s I think this project would be really fun and useful. Allow me to fork the project ;)\\n\\nThank youuu',\n",
       " 'This is God like!',\n",
       " 'Wow. What you did wlth AR is really creative and very impressive technically. Keep going dude you rock.',\n",
       " 'Holy fucking shit my jaw hasn’t dropped like this since I saw the GPT-2 demo. This is absolutely unreal—it is so precise + how the hell do they interact with macOS like that? Wow. Awesome work pal, so much respect.',\n",
       " 'Super cool demo.\\n\\nBut the more interesting part to me is the app actually look at the computer screen to decide what target the image/content is pasted to. \\n\\nProbably hard-coded, but super interesting idea.',\n",
       " 'This is amazing. Congratulations!!!',\n",
       " 'This is amazing! Thanks for sharing the code',\n",
       " 'Awesome! Recognize the catalog from Coder le Monde',\n",
       " 'That is so cool!',\n",
       " 'Awesome, will try it definitely.',\n",
       " 'Take my money',\n",
       " 'God this, and swiping a window to my laptop from my phone with a simple gesture, is what I have been waiting for sooo long.',\n",
       " 'cyberpunk level shit',\n",
       " 'Wow. Thanks for sharing!',\n",
       " 'This is really well done. From research to a simple yet useful use case!',\n",
       " 'beautiful',\n",
       " 'This is brilliant. Thanks for sharing...',\n",
       " 'Say sike 🤯🤯',\n",
       " 'Whoah',\n",
       " \"I saw this the other day and I thought it was incredible. I'm a novice on programming but ill do my best to deploy this on my PC just to play around with it! Thanks a lot for sharing this with the world!\",\n",
       " 'Smart move',\n",
       " \"That's some next level copy -paste !\",\n",
       " 'This is so cool! AI never ceases to amaze me.',\n",
       " '10 years ago people would laugh at this idea.',\n",
       " 'Wow this is so helpful, insane',\n",
       " 'This is so crazy!',\n",
       " 'So good it looks fake af',\n",
       " 'This is probably the coolest thing I have seen in a long while.  Great fucking work!',\n",
       " 'Wow, this is sick',\n",
       " 'You sir are a genius',\n",
       " \"What are the edges cases when this doesn't work? Does this require certain lighting conditions etc? How does it know to extract both people from the image?\",\n",
       " 'Very impressive, thought it was fake at first.... 🤪',\n",
       " 'Amazing!',\n",
       " 'Wow.',\n",
       " 'This gets 100 very nices',\n",
       " 'This is insane.',\n",
       " 'Man, this is awesome!',\n",
       " 'This is amazing. If you have any intention of publishing this as an end user app, hit me up, I’ll get make sure you get sponsorship for all the GPUs and other compute you need.',\n",
       " 'This is brilliant!',\n",
       " 'This is some crazy Tony stark shit',\n",
       " 'This is something really superb!!!!!!!!!!!  \\nI loved the technology...\\n\\nAI and Machine learnings are actually contributing a lot in streamlining our daily processes. I mean, this is something, being a student I would need the most, instead of first emailing myself pictures from phone, then downloading them and inserting them in my doc.',\n",
       " 'Woke up in the morning and this is the first thing I see. A day can’t get more inspirational.  I can’t thank you enough for sharing.',\n",
       " 'Wow, this is epic!',\n",
       " 'What is difference between this and taking photo and sending it with email to computer? 🤔 What is the main use case for this technology?',\n",
       " \"I really hope your idea doesn't get stolen. Also how do I keep up to date with your progress?\",\n",
       " 'Did you train the ML model yourself? If so what data set did you use?',\n",
       " 'How were you able to get integration with chrome and slides itself? Are you able to load custom software through Google Slides somehow?',\n",
       " 'How do I do this?',\n",
       " 'This is so cool! Is it really necessary to point the phone at the screen to paste it?  Or will it just paste it into whatever application is currently focused no matter what?',\n",
       " 'Does it work with text as well?',\n",
       " 'u/fabiomb el otro día decías que andaba porque tenía fondo de color blanco plano.',\n",
       " 'I\\'m more impressed with the background extraction on the photo than with the multidevice \"copy-paste\"',\n",
       " 'u/vRedditDownloader',\n",
       " 'u/VeedditDownloader',\n",
       " 'u/vredditdownloader',\n",
       " \"That's so cool\",\n",
       " \"There's no way that took 10s to develop, install, try and record an 57 sec video of. I mean, yeah, technology and stuff, but not in 10s. Sorry.\",\n",
       " 'I will go through the damn code line by line!',\n",
       " 'Is that a Google Pixel?',\n",
       " \"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:\\n\\n- [/r/mattslinks] [Augmented reality cut n paste](https://www.reddit.com/r/mattslinks/comments/ht7vs5/augmented_reality_cut_n_paste/)\\n\\n&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\\\\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*\",\n",
       " 'This is beast!! Deff on to something!',\n",
       " 'Awesome.',\n",
       " 'How do we use this',\n",
       " 'more more..More..MOREEEEEE',\n",
       " 'Dude...love ur copy paste...',\n",
       " 'Daaaaaaaam!',\n",
       " 'WITCH!',\n",
       " 'What the fuuuuuuuuck?',\n",
       " 'photoshop required ?',\n",
       " 'Omg! Thats awesome!!! I had a similar idea but using text',\n",
       " 'u/vredditdownloader',\n",
       " 'This is beyond science',\n",
       " 'My 5 years daughter thought of something similar..for her she wants that you take the object out of the screen and you show its hologram presentation..she said that would be a hard project to achieve :))\\nI will show her your project tomorrow, she will like it.',\n",
       " 'Oh sure. I find this after spending 29 days scanning in 21 years of issues of an instructional magazine on a flat bed scanner',\n",
       " '[deleted]',\n",
       " \"Really impressive if it works as well with unseen data.\\n\\nStill fun if it doesn't.\",\n",
       " 'This is clearly fake....the last screen shot proves it.',\n",
       " 'In 3 seconds if you use anything else then MacBook 😏',\n",
       " 'Ok, that’s the coolest thing I’ve seen in a long while.',\n",
       " 'This is awesome.',\n",
       " 'Tony Stark shit',\n",
       " 'Good job',\n",
       " \"Let we know when there's an easy and seamless way of doing this, or at least no-brainer\",\n",
       " \"The fact that they also had to know the location of the numbers and that the algorithm was robust to scale changes is impressive for 1993\\n\\nIt's not like they just solved MNIST in 1993, it's one step above that\",\n",
       " 'Every data scientist today is truly standing on the shoulders of giants.',\n",
       " 'TIL audio hasn’t been invented until 1994',\n",
       " 'awesome to see',\n",
       " 'And yet websites still think those obfuscated texts are a good test for robots',\n",
       " 'Anyone know who the other guys at the end are?',\n",
       " 'Never going to complain about not having a strong enough GPU again. Very cool.',\n",
       " 'Man, these guys were the real engineers.',\n",
       " 'Actually, he was 32 years old when he pressed the button. He was 33 by the time he got the results back.',\n",
       " 'Wonder what was the RAM and computing power of the system.',\n",
       " 'Many don’t know it, but before it was done such text recognition was considered impossible, just like AGI and other hard problems. I think text recognition in mail was the first successful real world application of AI.',\n",
       " 'MNIST irl',\n",
       " 'that was certainly more wholesome than the other historic computer vision video, [https://www.youtube.com/watch?v=8VdFf3egwfg](https://www.youtube.com/watch?v=8VdFf3egwfg)',\n",
       " 'But the question is: is it the validation set? 😁',\n",
       " 'Very inspiring as I remember these days. Lot of hard work and at the cutting edge.',\n",
       " 'Uh.  Sorry, no.\\n\\n[The CNN was invented by Hubel and Weisel in 1959, the year before Yann LeCun was born, under the name \"neocognitron.\"](https://en.wikipedia.org/wiki/Neocognitron) \\n\\nLeCun also didn\\'t make them first.\\n\\n[The CNN was first implemented by Kunihiko Fukushima in 1979](https://search.ieice.org/bin/summary.php?id=j62-a_10_658), 14 years before this video\\n\\n(Reference translated is Journal of the Institute of Electronics, Information and Communication Engineers A Vol.J62-A No.10 pp.658-665, October 25, 1979, ISSN 0373-6091)\\n\\nWhat Yann LeCun actually brought to the party was the modern approach to training them.  He did that in 1984, not 1993.',\n",
       " 'Nice keeb.',\n",
       " 'u/savevideo',\n",
       " 'That is so satisfying',\n",
       " \"The first set of numbers was Yann LeCun's phone number at bell labs.\",\n",
       " 'Still accurate than tesseract lol 😂',\n",
       " 'So why am I still doing captchas',\n",
       " \"Yann LeCun's tweet on who the other guys are, and who the cameraman is - \\nhttps://twitter.com/ylecun/status/1347268914263306242?s=20\",\n",
       " 'Better than tesseract',\n",
       " 'But still, to this date, they cannot recognize traffic lights',\n",
       " 'incredible! pay tribute to him',\n",
       " 'So why did it take 30 years to get this far?',\n",
       " \"On some comments about possible tweaks/tricks in this video:\\n\\nI have had the privilege to attend professor Yann's classes at NYU. \\nFrom whatever little I understand of him - he has high levels of integrity, and I do not see him trying some cheap tweaks and fixes...He was committed to solve a problem in the best way possible and not just for likes and hearts ☺️.\\n\\nAnd without high level of integrity, you can't go from lab to national level in short time. \\n \\nPeople often underestimate what it takes to be unanimously accepted as one of the godfathers of current hottest trend. This doesn't discount the effort of forefathers or future generations...\\n... but let's not undermine Prof's integrity and commitment by making such frivolous comments. In fact, it is only our loss, if we fail to see that.\",\n",
       " 'Cant see his right hand',\n",
       " \"Outside of the CNN achievements the rest is actually impressive too, and I'm absolutely amazed that the interface is so responsive. In 1993.\",\n",
       " \"I'll never understand why this didn't blow up like it should have when they succeeded in doing this. Should've been in the news all over the place for months.\\n\\nAI winter my backside\",\n",
       " 'What a boss!',\n",
       " 'Fukushima’s neocognitron came almost two decades earlier.',\n",
       " '[deleted]',\n",
       " \"So then what took so long for it to catch on? Why did it take another 30 years if they knew the power of cnn's?\",\n",
       " 'Amazing!  I’ve cited Professor LeCunn multiple times and am always humbled by his work — this is why I tell students that they are standing on the shoulders of giants when they do research.  Love this video!!!',\n",
       " 'That moving pharaoh will be my next sleep paralysis demon',\n",
       " 'I cant stop watching the actress, it’s like she’s studied Disney princesses all her life.',\n",
       " 'A friend of mine recently adapted this model for Skype, Zoom, etc. Very easy to install.\\nhttp://github.com/alievk/avatarify',\n",
       " 'Taken from https://twitter.com/AydaoGMan/status/1234531519349350402\\n\\nUtilizes First Order Motion Model for animation: https://arxiv.org/abs/2003.00196\\n\\nProject Page: https://aliaksandrsiarohin.github.io/first-order-model-website/\\n \\nCode: https://github.com/AliaksandrSiarohin/first-order-model',\n",
       " 'I want this done on The Scream',\n",
       " \"That's delightfully creepy\",\n",
       " 'Anyone think she looks like Elizabeth Holmes??',\n",
       " 'This could result very helpful to vtubers in the future',\n",
       " 'seriously impressive how different angles can be projected as well.',\n",
       " 'How can I see more that girl doing shit with her face?',\n",
       " 'What’s the painting in the top left though?',\n",
       " 'Kinda creepy. Can we train on this one from r/woahdude https://v.redd.it/iqptq372itu41',\n",
       " 'Sorry for the noob question, but what does \"first order\" mean here?',\n",
       " \"Hello, maybe this has been asked before but how can I get this software/ learn about it. I'm a motion designer with little knowledge of code but I'm willing to learn\",\n",
       " \"I honestly don't understand the hype as this is old news.  A team at Samsung AI demonstrated this with few-shot learning.  [https://arxiv.org/abs/1905.08233](https://arxiv.org/abs/1905.08233)\",\n",
       " 'how do you do this? like what program? its cool',\n",
       " 'Same can be done live via face2face.',\n",
       " 'Nefertiti is scary!',\n",
       " 'Amazing',\n",
       " 'Harry Potter moving paintings??',\n",
       " 'The pearl earring girl looks freakishly realistic',\n",
       " \"The Girl with a Pearl Earring looks like she's having a stroke\",\n",
       " 'Nefertiti looks so good',\n",
       " 'Nice.',\n",
       " \"Is there GAN for language? What's the best paper / code to watch?\",\n",
       " 'Does this remind anyone else about the moving pictures in Harry Potter?',\n",
       " 'Couldn’t stop watching Nefertiti. What a babe!',\n",
       " \"Lovely. But I wish I can hear what they're saying to me.\",\n",
       " 'Is it me or has this thread recently acquired a lot of members? This was posted yesterday, and now I believe it is the highest upvoted post.  After looking at the rules, I guess the crowdedness is more common on weekends.',\n",
       " 'Where can I test this out myself? Do I need my coding skills or a fast computer?',\n",
       " 'CUTE',\n",
       " \"It's perfect except for the wink\",\n",
       " 'Ahhh yes, now I am terrified',\n",
       " 'Nice',\n",
       " '[removed]',\n",
       " 'This seems like the next museum gimmick where you have an AR app, you point it to a photo and you get the person telling you their life story',\n",
       " 'Alan Turing',\n",
       " \"Does that mean we're supposed to find and share the link? Come on, op....\",\n",
       " \"I used some photos of my father and I'm speechless. He passed away when I was just a few months old, 29y ago. This is the first time I see him in motion, blinking, smiling... Thank you so much for this. ❤️\",\n",
       " 'This feels scary but I would love to give all my old pictures a spin.',\n",
       " '[cursed_cristiano_ronaldo_statue.mp4](https://streamable.com/rpxeuf)',\n",
       " '[deleted]',\n",
       " 'https://www.myheritage.es/deep-nostalgia',\n",
       " 'I love it when these things [break](https://imgur.com/a/bDISWZW) in the most spectacular and horrific of ways.',\n",
       " 'Just a warning, they will use it for porn',\n",
       " 'anyone know if github code exists for this? i would be curious to experiment with it',\n",
       " 'surprisingly poignant',\n",
       " \"To test it I put in some family pictures of people who are still alive and the results were frankly disappointing, awful even.  Uncanny valley mixed with nonsensical facial expressions mixed with inaccurate facial geometry.  More convincing for people you've never actually seen.  It may look like *somebody*, but not the real person in the photo.\",\n",
       " 'where is the link man',\n",
       " 'Harry Potter feels\\n\\nEdit : Context here was that Harry Potter universe has similar moving pictures',\n",
       " 'Link please?',\n",
       " '[deleted]',\n",
       " 'That’s Alan Turing isn’t it? Appropriate.',\n",
       " 'Alan would be happy if he knew',\n",
       " 'Where! Link?',\n",
       " 'Where is the URL ????',\n",
       " 'Will this Turing pass the Turing Test?',\n",
       " 'Sorry but not any link',\n",
       " 'Colab link please',\n",
       " 'uncanny valley presents: ...',\n",
       " 'Reminds me of Harry Potter and the paintings on the wall haha! Pretty cool',\n",
       " 'Link please?',\n",
       " 'Kinda creepy or am the only one that thinks this.',\n",
       " 'Anyone gets Harry Potter vibes ?',\n",
       " 'where the hell is the link?',\n",
       " 'Ahh, yes. Alan Turing, I backward-propagate?',\n",
       " 'Thats amazing. One step closer to Hogwarts.',\n",
       " 'tried this deep nostalgia from  myheritage serveral times...Just getting errors after uploading a picture',\n",
       " \"Can't wait until movies of history actually have historical figures in then. That's going to be cool as shit\",\n",
       " \"Wasn't able to cargando una foto for some reason\",\n",
       " 'Saw this on Reddit a few days ago and even though it looks a tad unnatural, it’s incredible to try(and it’s free). I’ve never met any of my grandparents but recently got photos of them so I spent the night watching my grandparents faces move through this app. Oh, the app also does a decent job colorizing the photos.',\n",
       " 'just insane...thanks for the link',\n",
       " 'I feel like he blinks to much. It was jarring',\n",
       " \"What's the difference between this and the first order motion model with a black and white filter?\",\n",
       " 're-animator',\n",
       " 'What kind of dark magic is this?',\n",
       " 'Harry Potter-esk. It is eery though',\n",
       " 'My heart',\n",
       " 'Well it passes the Turing test, aka the imitation game.',\n",
       " 'This reminds me of looking at a photo while tripping',\n",
       " 'straight out of a harry potter movie',\n",
       " 'Omfg it’s alive pls kill it with fire',\n",
       " 'Wow! That’s insane',\n",
       " 'Alan Turning',\n",
       " 'Earmarked',\n",
       " 'Creepy',\n",
       " 'I really wish AI would stop turning old photos into moving images',\n",
       " 'I think I saw this in Harry Potter',\n",
       " 'Maybe it takes a long time processing but it is amazing.',\n",
       " 'Wow this is cool!',\n",
       " 'This wouldn’t be able to get the correct facial movements and body language of the person though. Kinda ruins it for me',\n",
       " 'Do not! I repeat do not upload pics of your pets.',\n",
       " 'This is beautiful',\n",
       " 'Deserves an upvote',\n",
       " 'This is some Harry Potter shit.',\n",
       " 'This is some Harry Potter ass shit',\n",
       " 'Creepy/cool',\n",
       " '!RemindMe 12 hours',\n",
       " \"Does this work with less than great photos or super realistic art work? I have some not great photos of my great-grandparents and painted portraits of great-great-grandparents with family members that are in stellar to decent condition (not an art critic, but it looks amazing). We think we found some more paintings of older family members but we cant substantiate; additionally the detail and quality is far inferior to the later productions.\\n\\nI've never met anyone above grand parents, my mother was born to her parents at a late age, so I would love to try to animate my ancestors.\",\n",
       " 'Dame Dane',\n",
       " 'Where’s the link OP',\n",
       " 'What in the Harry Potter is that',\n",
       " \"That's stunning. Wow.\",\n",
       " 'Thank you for this, truly amazing',\n",
       " 'well this is next gen future. i will take look on my grandpapa lol.',\n",
       " 'No github? Some colab notebook ?',\n",
       " 'Link?',\n",
       " 'Wow!',\n",
       " 'Alan Turing woke up from his grave?',\n",
       " \"There's going to be a lot of racist pictures\",\n",
       " \"I saw the same thing in Harry Potter's newspapers. Hope those muggles cited them.\",\n",
       " 'Omg omg omg !!! Take my cash and i have millions of pics to be done ❤😍😍😍😍',\n",
       " 'Waiting for the first haunted house featuring moving olde tyme photos',\n",
       " \"I think it's possible. I'm working on a project that involves ai searching video based on keywords and would like to invite anyone to help.\",\n",
       " 'Interesting. Thanks for sharing!',\n",
       " 'Can somebody explain me why it is scary??',\n",
       " \"That's some Harry Potter shit\",\n",
       " '[deleted]',\n",
       " 'That’s Allen Turing he was one of the people who broke the enigma but after the war he got persecuted for being gay because in England it was illegal to be gay and and the made him take testosterone shots because they thought it would make him not gay but it messed with his mind and did not do well for his body and what basically led up to his suicide. Sorry for the long rant',\n",
       " 'Is that Alan Turing?!!!???',\n",
       " 'u/savevideo',\n",
       " 'This reminds of the moving pictures in Harry Potter lmaooo',\n",
       " 'https://www.google.com/amp/s/bigthink.com/amp/new-ai-can-create-fake-videos-of-people-from-a-single-picture-2638041019\\n\\nThis is an article with more examples that also links to the paper',\n",
       " 'Harry: you always can',\n",
       " 'Givin the ol Harry potter treatment',\n",
       " \"Who would ever have said that 'Harry Potter' was a science fiction book....\",\n",
       " 'Turing would be proud. Very cool work.',\n",
       " 'does it pass the Turing test tho lol',\n",
       " 'Hello Harry Potter moving newspapers',\n",
       " \"Hey, it's some cool Harry Potter shit!\",\n",
       " 'I realized that in Harry Potter this technique is already implemented a long time ago.',\n",
       " 'Where we can find the code for this to implement it for our own old photos?',\n",
       " 'That is creepy af',\n",
       " 'Looks cross-eyed. Was he?',\n",
       " 'From first computer fundamental to Artificial intelligence',\n",
       " 'Bleah.  Saw this in Interview With the Vampire 30 years ago.',\n",
       " 'Oh pleease, this isnt an \"old photo\"; its Nicholas Hoult. AI my booty.',\n",
       " 'This honestly feels like those paintings in Harry Potter.',\n",
       " 'Can someone explain the exact way to do this please ?',\n",
       " 'I don\\'t know why but I want to hang this on a wall as a \"painting gif\"',\n",
       " 'Interesting, what ML algorithm is behind this?',\n",
       " '[removed]',\n",
       " 'Voting takes forever. What exactly are they \"supposed\" to be doing during a time when they\\'re not allowed to talk to their neighbors? This is just \"look busy\" toxic work culture lol',\n",
       " 'The title is a bit misleading, since the percentage of each rectangle is most likely the confidence of the classifier that detects these objects. It is not the percentage of time each individual uses their phone in.',\n",
       " 'Afaiik this is actually an art project, designed to showcase surveillance and make politicians aware they are being surveilled too.',\n",
       " \">Every meeting of the flemish government in Belgium is live streamed on a youtube channel. When a livestream starts the software is searching for phones and tries to identify a distracted politician. This is done with the help of AI and face recognition. The video of the distracted politician are then posted to a Twitter and Instagram account with the politician tagge\\n\\nSo, this tries to identify 'distracted' politicians, but only includes phones and excludes staring at laptops and tablets - for some reason? Is there a reason?\\n\\nAll I see is a system that detects whether some politician is using their phone or not.\\n\\nDisregarding my (negative) biases towards politicians, this honestly says nothing of whether they're distracted or doing productive/non-productive work on their phones/tablets/laptops.\",\n",
       " '[deleted]',\n",
       " 'Better create a sleeping detector',\n",
       " 'All this shows is that you can successfully detect a phone and maybe a politician in the picture. \\n\\nIt doesnt say anything about \"how much time\" or even about whether them staring at the phone is equivalent to them being productive or unproductive. \\n\\nAlso, this looks like a simple object detection algorithm. It is not AI. It is a computer vision algorithm. \\n\\nIt is time we start using the right terminology, be accurate in our descriptions of what the work is about and lastly, stop overestimating our work.',\n",
       " 'Staring at phone may not always be unproductive if that is what being implied by this study. Lot of useful work is being done using phones now a days.',\n",
       " \"So probalistic facial recognition and smartphone utilization? How do you, or the viewer, know that they're not working?\",\n",
       " 'what you should do is show the amount of time they spend with each lobbyist.',\n",
       " 'Soon: Your employer bought this AI that tells them how long you look at your phone at work. They use this to rank you against your peers to determine career progression.',\n",
       " 'Cute project, utterly worthless at producing any valuable insights.',\n",
       " 'Amazing. Now we just need a model to determine how much of that time is spent watching porn and playing Raid Shadow Legends.',\n",
       " \"So, laptops and tabs/tablets are fine, phones are not.\\n\\nthey can be taking notes or working.\\n\\nIf its so important make a no phones rule, otherwise that's like judging a lions hunting ability by the time it sleeps.\",\n",
       " \"Not useful in Italy. A lot of them doesn't even show up in parliament...\",\n",
       " \"So, politicians are also human. I can't say I'm even a little surprised.\",\n",
       " 'I hate politicians as much as the next person… but they could just as easily be doing work on their phones.  It is how people communicate after all.',\n",
       " 'This reminds me of boomer comics',\n",
       " 'Does that mean they are on Reddit ?',\n",
       " 'This is kinda terrifying. Maybe you find it funny when it’s politicians, but what happens when corporations turn this dystopian tech on their employees? \\nI love machine learning, but we absolutely needs regulations on things like this.',\n",
       " 'Source: https://driesdepoorter.be/theflemishscrollers/',\n",
       " 'Genius, now maybe we should tell their mood based on their facial expressions',\n",
       " \"People are way too focused on the why and not enough on the what.\\n\\nWho cares that it's not a perfect representation of how distracted they are? Who cares if they're doing actual work or not on their phone? This is not about that, this is about an AI that can determine whether you're on your phone or not. That's it!\\n\\nWhy everything needs to be political?\",\n",
       " \"I do at least 30 percent of my research (e.g. reading papers) and 50 percent of my business (following leads, LinkedIn, etc) on my phone. So I should be cancelled because I'm working hard on my phone? Dumb.\",\n",
       " 'Great project',\n",
       " 'O! I think this is ImageAI(module for python)',\n",
       " 'What about tablets and computers?',\n",
       " 'Ain’t they voting?',\n",
       " 'Need to know the pr0n ratio',\n",
       " 'Skynet in the early stages of learning about its future foe',\n",
       " 'Why do we need an AI for this? You can literally just see them staring at their phones. This is such overkill.',\n",
       " \"I bet they don't like having their identity known by facial recognition. 🤭\",\n",
       " '\"Reveals\" and \"stare\" are loaded terms that don\\'t belong here.',\n",
       " 'Need to watch the live porn',\n",
       " \"Lol at Jan Jambon. Glad I didn't vote for him.\",\n",
       " 'Checkin their crypto portfolio. Oh wait they are old dinosaurs. They dont have crypto. Just playing Candy Crush.',\n",
       " \"The politicians staring at their tablets instead: I don't have such weakness.\",\n",
       " 'White=how sure that its that politican \\nGreen=how sure that its a phone',\n",
       " 'I hate how little care most politicians have for their job. \\n\\nWell I guess they work to keep their positions but I feel like after that it’s pretty minimal effort. We should lower their wages.',\n",
       " 'I guess being on an iPad doesn’t count lol.',\n",
       " \"To be fair their job is to lie to their constituents on Twitter, emails and Facebook and to vote the way their corporate sponsors tell them to. If they don't have phones they would have to remember what to lie about all in their heads. It can be exhausting remembering all the lies and keeping it all straight.\",\n",
       " \"Very misleading op title and overall low quality discussion in the comments. \\n\\nI don't know but something about this post doesnt really fit with the sub, and I don't know if there is a rule or moderation approach that can keep that in check\",\n",
       " 'This job must be boring',\n",
       " 'use this in Albania',\n",
       " 'Should be combined with an reward system for not using the phone during the work haha',\n",
       " 'Everyone trying to squeeze out final drops from our poor cow.',\n",
       " 'That is why I read conclusion section first and most papers fail me there',\n",
       " 'The \"We proved a thing that\\'s been known empirically for 5 years\" paper is really usefull tho. It allow you to have a solid justification on your use of that \"thing\" in your/all next researches.',\n",
       " '\"We rediscovered something known 30 years ago and we didn\\'t cite it\"',\n",
       " 'Stop requiring your PhDs to have 10 publications before they graduate and half the issues will solve themselves.',\n",
       " 'The unreasonable effectiveness of cliche titles in papers is all you need.',\n",
       " 'As a biologist, this is most papers in that field too.',\n",
       " 'As I am always saying: No papers about „we used hardcore mathematics and developed a new method“.\\n\\nOh just saw that in line 3, column 2 there is the kind of research which goes into that direction.',\n",
       " 'Hahahaha. \\n\\nBottom left corner is why I left ML reasearch. What was ridiculous was CVPR actually accepting the <1% improvements.',\n",
       " 'The Lego bit had me in stitches.',\n",
       " \"has anyone here ever wrote a paper? I'm supposed to write one for my university and I've never wrote one before, like what tools do you use to get the pdf and what other stuff should i know?\",\n",
       " '[deleted]',\n",
       " 'Thank God that the scientific method can be applied to computer science. 🤪',\n",
       " 'The Lego block paper is one of the reasons I decided not to do a Phd',\n",
       " '>\\\\[...\\\\] this time, I swear\\n\\nThis one got me good.',\n",
       " \"This is a very depressing testament to the state of the field. It's all true.\",\n",
       " 'You forgot the GAN puns.',\n",
       " \"Lego block paper writer here, tru tru\\n\\nadmittedly I'm a soft.eng. with chem flavor phd that uses machine learning not a researcher in machine learning\",\n",
       " '“Here’s another game that we ruined”',\n",
       " \"I see a lot of comments talking about all the short comings of ML. How there are too many people in the field, how there are not enough, too many graduate students, requirements are to strick or too lenient. \\n\\nAs someone who is about to enter grad school, in ML, and who is committed to the idea of being apart of this apperant broken machine. How can I be apart of the change that results in something better? Sure, read more papers, be better at research, be more creative, blah blah blah, descriptors that are easy for the experienced to understand and impossible for the young and learning to interpret. \\n\\nThe reason that science seems to be only nudged by the many and truly pushed by the few is because, in my opinion, success is hardly documented and faults and critism are plentiful. I think if more were willing to mentor, teach and share then we could see more progress. I know I could be better.\\n\\nFinally, we need a less hand wavy approach to learning how to research. The best I have learned about and getting a mentor, hoping he/she will take you under their wing and emulate as much as possible. Research shouldn't require a parent. I don't have a better solution unfortunately but i wish there was one.\",\n",
       " 'Credits: Maxhkw (Twitter)',\n",
       " 'What is AGI?',\n",
       " 'as a phd aspirint this frightens me to the core',\n",
       " 'The resources these researchers consume to do 0.1% improvement is ridiculous. Like, have they even played Minecraft in their life? \\n\\n&#x200B;\\n\\nLimited resources, limited life, limited money. Optimise and use wisely.',\n",
       " \"Isn't one problem that students have to write a couple of papers in their educational career and there is only so much groundbreaking research possible at a time?\",\n",
       " 'I feel attacked',\n",
       " 'Grear meme that requires actual research experience to make.',\n",
       " 'Lol',\n",
       " 'Since when did the sub start accepting memes??',\n",
       " 'i hate the ones that begin with \"towards..\". why the tf would i want to read something that\\'s incomplete?',\n",
       " 'You forgot the usual \"Here\\'s a theory with no applicable results, nothing to prove that it\\'s true or that it works, but now that we\\'ve done this we hope someone will do all the job to prove we were right\"',\n",
       " '[deleted]',\n",
       " 'God this is so accurate. I love it!',\n",
       " 'Missed opportunity for a Schmidhuber meme.',\n",
       " 'I love every one of these, but the deep learning one hits most home to what I have to deal with . ;)',\n",
       " 'Omg I love this! Hilarious and a bit accurate on the literature survey!',\n",
       " 'Which type do you like the most?',\n",
       " 'bahahahha fucken oath',\n",
       " 'Did you guys hear that in a medical journal someone figured out how to compute the area under a curve?\\n\\nhttps://care.diabetesjournals.org/content/17/2/152.abstract',\n",
       " 'In [Machine Learning](https://www.tibacademy.in/machine-learning-training-in-bangalore/), we have lot to learn and some of the papers had shows here. Keep up the good work',\n",
       " 'Nice one!!! .. i have been time and again fooled by \"*we have figured out how deep learning generalizes this time, i swear*\" only to be fooled by another similar paper...This really wracks my brain...and makes me question myself',\n",
       " 'We invented <<replace this>> in our lab in 1991.',\n",
       " 'BS++:We add a small bs on my old bs and the accuracy improves 0.01%',\n",
       " \">Thirdly, there is a worshiping problem.\\n\\nThank you. I was going to make a meta-post on this topic, suggesting that the subreddit put a temporary moratorium on threads discussing individual personalities instead of their work—obvious exceptions for huge awards or deaths. We need to step back for a moment and consider whether the worship culture is healthy, especially when some of these people perpetuate the toxicity you're writing about above.\",\n",
       " 'We actually wrote a paper regarding some of the above points. Kind of a self-criticism: https://arxiv.org/abs/1904.07633\\n\\nSome other points we touched:\\n\"lack of hypothesis\" & \"chronic allergy to negative results\" \\n\\nAnd we discussed (without claiming always applicable) the possibility of results-blind peer review process.',\n",
       " \"Some of these are rampant in academia in general, what hasn't happened elsewhere is the spotlight (and $$$) that has been thrown at CS/ML in past few years.  We see what fame/fortune does to a lot of people (outside academia) we are not immune to the lesser parts of human behavior.\",\n",
       " 'This is common in academia. Still worth criticisizing if it makes any difference.',\n",
       " \"Thanks for writing this. I can strongly attest the 'publish or perish' mentality. In my experience, ML researchers seem to live on an entirely different planet revolving around NeurIPS and/or CVPR. The first thing a guy I had to work with on a project asked me was the acceptance rate of the conferences I publish at. I am not even a ML researcher. Entirely ridiculous. Most of them truly have a huge superiority complex they should address.\",\n",
       " '>**Thirdly,** there is a *worshiping* problem. Every paper with a Stanford or DeepMind affiliation gets praised like a breakthrough. For instance, BERT has seven times more citations than ULMfit. The Google affiliation gives so much credibility and visibility to a paper.\\n\\nI totally agree with the premise... but, I think a lot of people forget just how easy it was to load up BERT and take it for a spin. The effort the authors put into the usability of the model helped immensely.',\n",
       " \"TLDR; politics sucks. Unfortunately, you can never escape politics, no matter which field you escape to. I started doing scientific research because I imagined the system to be a fair meritocracy. It's science after all. If you don't like politics, academia is one of the worst places to be. This is the sad truth. This is not a recent phenomenon, and it's not just ML. It has always been this way. It's just more visible now because more people are new to the field and surprised that it's not what they expected.\\n\\nAs long as the academic system functions the way it does and is protected by gatekeepers and institutions with perverse incentives, this will never change. What can you do? Lead by example. Don't play the game and exit the system. Do independent research. Do something else. Don't be driven by your ego that tells you to compete with other academics and publish more papers. Do real stuff.\\n\\nIt's very difficult to reform a system from within. Reform comes when enough people decide to completely exit a system and build an alternative that has a critical mass.\",\n",
       " 'In other words, humans bad.',\n",
       " \"Money and fame.\\n\\nAlmost all of what you describe comes from newer people who want fame (cite me!) more than advances in science. It's because with the (somewhat justified) hype around ML in the industry, fame turns you into a millionaire.\\n\\nJust wait until there is no longer money falling from the sky in this field, and all those toxic persons will simply vanish like a gradient in an MLP too deep. With them, the factual problems with reviews and reproducibility will also vanish, and things will be enjoyable and rigorous again.\",\n",
       " 'Wow, this post is making me *seriously* rethink applying for an ML graduate program.',\n",
       " 'Albert Einstein was absolutely *not* opposed to quantum mechanics, by any stretch of the imagination. Saying Einstein was opposed to QM is like saying Alan Turing was against computers; Einstein was one of the founding fathers of QM.\\n\\nWhat Einstein took issue with, was the Copenhagen interpretation of QM.  Many/most physicist working in foundational QM today share his view on that.',\n",
       " 'Yes this is just crazy how hard the ML community manages to clash and tear itself apart regularly. \\nI follow both the physics community and the ML community and it’s quite hard to imagine physicists trash talking this hard and politicizing every aspect of their research. Ok ML has social influences but this is just ridiculous to see people pushing their political beliefs through their research ...\\nConcerning reproducibility and the race to publish I think it’s simply because ML is extremely competitive with regard to other fields (physics for example).',\n",
       " \"The focus on quantity over quality is a big one. We should be focusing on quality research instead of trying to increase our publication count. Also, the focus on just throwing more data at larger models like GPT-3 is a super bad direction for the field to be going in. Rather than actual innovation it's just larger models and more data and making things even more exclusive to the large companies and labs with 1000s of GPUs and tons of funding and resources.\",\n",
       " '> papers by well-known institutes that were put on arXiv are accepted at top conferences, despite the reviewers agreeing on rejection.\\n\\nWait, can someone provide an example of this?',\n",
       " \"> If you don't publish 5+ NeurIPS/ICML papers per year, you are a loser\\n\\nNo, that's not true. You're only expected to publish 5+ papers every year in your 4th / 5th year Ph.D! Before then, you're only expected to publish 2-3 papers a year, and before Ph.D as undergrad or masters you only need 1-2!\",\n",
       " 'I don\\'t think LeCun was insensitive. I think he was *painted* insensitive after the fact, but what I saw was him taking a stance, documenting it, being personally attacked without any reply to his arguments, and then dismissed with \"if you aren\\'t a black woman you have no right to talk\", which is ridiculous.\\n\\nWhat\\'s doubly annoying is that I *wanted* to see a counterpoint to LeCun\\'s arguments, because I wanted to learn more about what the problem is and see what it was he was missing, but the counterargument was \"you aren\\'t black so you\\'re wrong\". I left that debate thinking LeCun was right and that some people do the racial struggle a disservice by being entitled and trying to blame racism for anything they don\\'t like to hear.',\n",
       " 'This stuff is almost directly related to the size of the field. I started in the speech recognition field when it was a sleepy niche field. The conferences were collegial, people knew each other and their various pet projects.\\n\\nThe moment speech recognition became commercially viable, the conferences drastically changed.  The big guns swooped in and entirely dominated the conferences, the papers had the same problems OP described, with little scientific value, just gaming the process to get a higher number nobody could produce.',\n",
       " '>**Secondly,** there is a *reproducibility crisis*.\\n\\nI am working on 3D Pose Estimation and I really feel this problem right now! There aren\\'t that many datasets and most papers use the dataset \"Human3.6M\". Its large, but also very specific. So many projects tweak the \"postprocessing\" so that they account the specific setup of Human3.6M ... and so my results on \"free living samples\" are worse.',\n",
       " '[deleted]',\n",
       " \"Btw, this race to publish strongly encourages publication with few experimental soundness and that don't improve on nothing but rather are just telling a story that is sound ( unfortunately sound stories rarely are able to justify deep learning successes ). Then verify it by few experiments obviously discarding any of them that would disprove the initial claim ... I feel like I spent one year reading such papers to realize the field I'm working on has not advanced an inch ... Then you obviously see papers like 'reality checks' to denounce that, but still more useless paper are coming out every day.\",\n",
       " 'Forgive me for being new. But what is this obsession with releasing new papers? Is papers seen as some way to get a salary or something? If you really wanted to do AI research, would it not be better to be payed by a private company?',\n",
       " \"You are correct, but it's not a problem for ML specifically ,it's a general problem. We are living in strange days, where it's not about what you do/publish, but with whom you are associated. We have an inflation of paper submissions, because we use it as an KPI. We have diversity issues, because we involving color, gender in our criteria to form a team. It's not about who you are, it's about what sex, color or whatever you have. We need a diversity of mindset, not of biological features. Saying you don't consider race as a criteria, makes you a racist. Insane.\",\n",
       " '>The moment we start silencing people because of their opinion is the moment scientific and societal progress dies.\\n\\n\"Science progresses one funeral at a time\"\\n\\nhttps://en.m.wikipedia.org/wiki/Planck%27s_principle',\n",
       " \"I’m really disappointed with how Anandkumar acts on Twitter. For example, [she said “you are an idiot” to a ~~high school student~~ young researcher](https://twitter.com/carlesgelada/status/1248693492039053312?s=21) for suggesting that we only teach about neural nets in ML classes. \\n\\nShe deleted the reply but then [tweeted out another response](https://twitter.com/animaanandkumar/status/1248332790090756096?s=21), again referring to the original tweet as “idiocy”. \\n\\nHow someone can do things like this and be a director at Nvidia and have 30k followers is beyond me.\\n\\nEdit: Apparently he isn’t a high school student, sorry for the mistake. My point was mainly that public figures shouldn't make personal attacks on young researchers, or anybody for that matter. \\n\\nTo put it another way: imagine if a white male researcher called a young female researcher an idiot on a public forum. Many (including myself) would find that to be unacceptable. Yet Anand seems to have gotten away with it here.\",\n",
       " 'I hope your comments about the broad, chilling social impact of this work don’t go unnoticed',\n",
       " \"Thanks for writing this up. Many of these problems exist across all academia though. The big underlying problems are our ancient, outdated ways of communicating scientific findings (separate manuscripts and prose that can only be updated by completing a new project) and the way we do scientific quality checks (an, in practice random selection of 2-3 community peer reviewers). Also, a belief in an only recently established incentive system (number of completed projects written up in manuscripts) that might increase the overall amount of completed projects, but is often to the detriment of quality and increases the amount of shoddy research and researchers in the system.\\n\\nThe first two problems only exist because submitting papers to peer review was the best that could exist before the digital age. The system has just not been adapted to the digital age yet because people who currently have most power did not have their formative years in this age, and either don't realise its possibilities or are dissatisfied by the ancient ways too, but know that substantial changes are better left to the new generation.\\n\\nIt is in the hands of the current, new generation of scientists to change the scientific system for the better, and move it to the digital age. We all realise its problems and don't have to submit to problematic practices thats improvements are overdue.\",\n",
       " \"i will never voice my opinions in academia because i don't want to risk being cancelled. but i agree with majority of this post.\",\n",
       " 'I totally agree with 99% of your stuff. All of them are great points.\\n\\nAlthough I will contest one of these points:\\n\\n> machine learning, and computer science in general, have a huge diversity problem\\n\\nI will say, in my experience, I did not find it to be particularly exclusionary.                      \\n(I still agree on making the culture healthier and more welcoming for all people, but won\\'t call it a huge diversity problem, that is any different from what plagues other fields)              \\nI also think it has very little to do with those in CS or intentional rejection of minorities/women by CS as a field.\\n\\nFar fewer women and minorities enroll in  CS, so it is more of a highschool problem than anything. If anything, CS tries really really hard to hire and attract under represented groups into the fold. That it fails, does not necessarily mean it is exclusionary. Many other social factors tend to be at play behind cohort statistics. An ML person knows that better than anyone.               \\n\\nThere is a huge push towards hiring black and latino people and women as well. Far more than any other STEM field. Anyone who has gone to GHC knows how much money is spent on trying to make CS look attractive to women. ( I support both initiatives, but I do think enough is being done) \\n\\n\\nA few anecdotes from the hackernews thread the other day, as to greater social reasons for women not joining tech.\\n\\nSample 1:\\n\\n> There\\'s one other possible, additional reason.\\nI recently asked a 17-year-old high school senior who is heading to college what she\\'s planning to study, and she said it would be mathematics, biomedical engineering, or some other kind of engineering. She\\'s self-motivated -- says she will be studying multi-variate calculus, PDEs, and abstract algebra on her own this summer. She maxed out her high school math curriculum, which included linear algebra as an elective.\\n\\n>Naturally, I asked her about computer science, and she said something like this (paraphrasing):\\n\\n> \"The kids who love computers at my high school seem to be able to spend their entire day focusing on a computer screen, even on weekends. I cannot do that. And those kids are mostly boys whose social behavior is a little bit on the spectrum.\"\\n\\n> While I don\\'t fully agree with her perspective, it makes me wonder how many other talented people shun the field for similar reasons.\\n\\nSample2: \\n\\n> My niece had almost the exact same opinion despite having multiple family members who didn\\'t fit that description, including her mother! It wasn\\'t until I introduced her to some of my younger female co-workers that she committed to being a CS major. She\\'s now a third generation software engineer, which has to be fairly unique.\\n\\n> I\\'ve talked to her about it and she can\\'t really articulate why. I\\'m closer to the nerd stereotype in that I\\'m on the computer a lot but her mother (my sister) definitely is not. I think it\\'s mostly pop and teen culture still harboring the antisocial stigma. I\\'ll have to talk to her some more.\\nThere is probably some connection with video games, in that boys overwhelmingly play games where girls do not. I don\\'t think the games cause the disparity; whatever it is that draws boys to VGs is what draws them to CS as well\\n\\nYou can\\'t blame the field for being unable to fight off stigma imposed by 80-90s movies on an entire generations.\\n\\nFor example, there is no dearth of Indian women in CS. (I think it is similar for Chinese people too). Both societies did not undergo the collective humiliation of nerds that the US went through, and CS is considered a respectable \\'high status\\' field, where people of any personality type can gel in. Thus, women do not face the same kind of intimidation. This is a \"US high school and US culture\" problem. Not a CS problem. \\n\\n> Going on parental leave during a PhD or post-doc usually means the end of an academic career. \\n\\nTo be fair, this is common to almost all academic fields. CS is no exception and I strongly support the having more accommodations for female employees in this regard. \\n\\nHonestly, look at almost all \"high stress, high workload\" jobs and men are over-represented in almost all areas. Additionally, they tend to be a very particular kind of obsessive \"work is life\" kind of men. While women are discouraged form having such an unhealthy social life, men are actively pushed in this direction by society. IMO, we should not be seeking equality by pushing women to abide by male stereotypes. Maybe, if CS became a little better for everyone, it would benefit all kinds of people who are seeking healthier lives, men and women alike. This actually flows quite well into your next point of \"cut-throat publish-or-perish mentality\".',\n",
       " \">In contrast, vice versa, some papers with a majority of accepts are overruled by the AC. (I don't want to call any names, just have a look the openreview page of this year's ICRL).\\n\\nI agree with a lot of what you are saying, but I think this point is a bit unfair. I've encountered situations where 2/3 of the reviews are glowing, but there are pervasive, major errors in the mathematical descriptions of things. The paper doesn't make sense.\\n\\nI think there are serious issues with getting enough competent reviewers to deal with the deluge of ML papers being submitted right now and that many reviewers, including well qualified ones, are not putting enough time into reviews.\\n\\nFor me to do a thoughtful review (I've been reviewing for NeurIPS, ICML, AISTATS for 6 years) takes me *at least* 5 hours per paper. I see people saying that they spend <2 hours per review. The following is a particularly egregious example of this, a professor at a world-class university *starting his reviews 2 days after the deadline*:\\n\\n[https://imgur.com/a/hfUIhZz](https://imgur.com/a/hfUIhZz)\\n\\nBecause of this its becoming more crucial for the ACs and meta-reviewers themselves to make  judgement calls on papers' worthiness and cannot rely so much on the reviewers.\\n\\ne:formatting\",\n",
       " 'I’d add (your post being an example, no offence):\\n\\n**Eighthly**: an under appreciation of the importance of statistics. As we know there’s the CS side and statistics side of ML. The former of which are notoriously dismissive of the importance of the latter. To the point that statistics has almost become a loaded term in the mind of many from the CS side. I myself have had discussions with people here who have literally said that any knowledge of statistics is entirely useless in ML. So let’s remove the word statistics and focus on (some of) the important aspects that having a strong understanding/appreciation of statistics provides, such as the ability/realisation that understanding the subtle assumptions made in the technique(s) developed are crucially vital. \\n\\nOk some times taking a pragmatic approach rather than tying yourself in knots worrying about inherent assumptions in your technique can speed progress, but it’s also vital in understanding the limitations of your technique and where it will breakdown - not only from an algorithmic/numerical standpoint, but from a reproducibility standpoint. I’d argue this is an important causative factor in why your second point exists.',\n",
       " 'On point no.6, *moral and ethics*:\\n\\nIn 2019, [Yoshua Bengio tried to promote a new set of guidelines](https://www.nature.com/articles/d41586-019-00505-2 ) developed by a group of not only AI experts but also ethics experts. **You can read the declaration [here](https://www.montrealdeclaration-responsibleai.com/the-declaration)**\\n\\nUnfortunately, adhering to these principles is still entirely voluntary and it hasn’t caught on. **You can see the limited list of organizations who have already signed [here](https://www.declarationmontreal-iaresponsable.com/signataires).**\\n\\nIgnoring the fact there is no clear framework for holding the adhering organizations accountable, it would have been nice to see the community at least adhering on principle.\\n\\nEdit: As a constructive actionable item, you can still sign the declaration as an individual practitioner, or you could advocate for the organization you work for to sign it.',\n",
       " '> discussions have become disrespectful. Schmidhuber calls Hinton a thief, Gebru calls LeCun a white supremacist, Anandkumar calls Marcus a sexist, everybody is under attack, but nothing is improved.\\n\\nYoshua Bengio is the liberal Canadian knight that will deliver this community.',\n",
       " '> Secondly, there is a reproducibility crisis. Tuning hyperparameters on the test set seem to be the standard practice nowadays. Papers that do not beat the current state-of-the-art method have a zero chance of getting accepted at a good conference. As a result, hyperparameters get tuned and subtle tricks implemented to observe a gain in performance where there isn\\'t any.\\n\\nPPO Anyone?\\n\\n> Secondly, there is a reproducibility crisis. Tuning hyperparameters on the test set seem to be the standard practice nowadays. Papers that do not beat the current state-of-the-art method have a zero chance of getting accepted at a good conference. As a result, hyperparameters get tuned and subtle tricks implemented to observe a gain in performance where there isn\\'t any.\\n\\n> Thirdly, there is a worshiping problem. Every paper with a Stanford or DeepMind affiliation gets praised like a breakthrough. For instance, BERT has seven times more citations than ULMfit. The Google affiliation gives so much credibility and visibility to a paper. At every ICML conference, there is a crowd of people in front of every DeepMind poster, regardless of the content of the work. The same story happened with the Zoom meetings at the virtual ICLR 2020. Moreover, NeurIPS 2020 had twice as many submissions as ICML, even though both are top-tier ML conferences. Why? Why is the name \"neural\" praised so much? Next, Bengio, Hinton, and LeCun are truly deep learning pioneers but calling them the \"godfathers\" of AI is insane. It has reached the level of a cult.\\n\\nI don\\'t want to point fingers but there\\'s marginal improvement in DQN over NFQ but the former has over an order of magnitude more citations than the latter and the difference between the two is who had more compute to test stuff and more memory to store all the 10M transitions....',\n",
       " 'https://twitter.com/adjiboussodieng/status/1277599545996779521?s=19\\nAnother instance of accusation of misogyny and racism without any basis. Could have just asked about not citing without accusations and playing victim.',\n",
       " \"Perhaps we need a new conference that gives equal merit to negative results. Makes publishing preprints that are not anonymous (and not shared by the author on twitter) and that makes some improvements with the peer-review process so it's less arbitrary. \\nI feel like by focusing on merit rather than names that would alleviate some of these issues. Perhaps open discussion could be promoted/rewarded somehow also? and additionally inappropriate conduct punished in the same way. Focus on the science and the ideas not the people\",\n",
       " 'Thank you for writing this. I’ve been observing these things as well, and I think you’ve articulated them very well. I wouldn’t be surprised if a majority of those in the ML community share much of your views.',\n",
       " \"Moral and ethics should be part of the curriculum in ML education and paper discussions. If we do not educate people then it's hard to control what any company could do for the sake of profit. I still feel disgusted to have found in a research showcase presentation a database field called IsUyghur. Apparently the subsidiary research lab in China from a silicon valley company was responsible for it. Funny that the company wanted to join people together.\",\n",
       " '[deleted]',\n",
       " \"I strongly agree with you on the first 3 points. For point five I think you underestimate how good 30% is, in mechanical engineering only 13% of B.S. are going to women and electrical engineering is only 12%. Not to say that we are perfect, but 30% is progress. For six I think you leave out that a large portion of research is conducted in the US. So it makes sense that people would be very concerned with the US policy and ignorant of the PRC use of the technology. \\n\\n&#x200B;\\n\\nIf you want to discuss further feel free to DM me, I'm literally always down to talk about the state our field and how some of it is a complete shit show.\",\n",
       " \"Amen. Academia and especially the ML community have a huge vanity problem - extremely arrogant, dismissive, and even unethical. I'd love to work on a solution to all of this.\",\n",
       " \"Good discussion. I'm not sure what I can do to help the problem. But I will always support any effort to suppress toxicity.\",\n",
       " 'Every single issue listed here is right on the money. I am an MSc student at a top uni and although I have published a few papers in top conferences, the absolute stress and mental headache of the publish and perish mentality and the broader issues mentioned here is strongly motivating me to not pursue a PhD, although I had been set on doing so for a great while.\\n\\nFor the first year of my masters, I was constantly reminded that I don\\'t yet have a published paper yet, and without it (or some amazing internal references/connections) access to good research internships are rare, and without that, goes the chance to build connections and get exposure (the deepmind, Google hype that OP mentioned) that is crucial for success deeper into PhD and beyond. It\\'s as if every step from the day you start uni must be perfectly placed, lest you be banished to academic wilderness. It also didn\\'t help that my work was not in neural net/CV/NLP but in game theory+ML which is more niche meaning less visibility, less interesting to industry and others, and so on. Ofc, one does not and should not do research for \"visibility\" or \"hype\" or to publish only in a handful of venues skewed toward deep learning, but unfortunately this seems like the reality of our field. A great many days I honestly felt like I part of some strange cult and wondering what the hell I\\'m doing here. Even after publishing papers, I didn\\'t feel this anxiety reduce by much.\\n\\nI honestly loved the work I did and the advisor and peers I worked it, who were all amazing. However, the broader setting is just deeply toxic. ML grad school feels like the cut-throat, constantly selling you and your work, virtue signalling yet indifferent mentality of industry combined with poverty wage and financial struggles of grad school.\\n\\nI hope that as a community, we listen and act instead of paying lip-service, accept that negative results and failed attempts are an important part of scientific research and not every paper must be SOTA to be meaningful, realize the myriad pressures grad students are under and setting the minimum threshold of success to be k papers/year at n conferences/journal doesn\\'t make a great researcher but rather burnout or reward-hacking, stop putting certain people on pedestals, and we critically question the merits of industry dominating academia with half of top profs/departments being in their payroll in the name of some platitude.',\n",
       " \"> However, the *toxicity* and backlash that he received are beyond any reasonable quantity\\n\\nThere are many vocal people in DS and tech in general who think critical theory is the only lens to examine the world through rather than it being one of many. It's a real problem and makes it next to impossible to have a conversation with these people. My guess is most of them don't even realize they are engaging in a dialectic which embraces subjective truth. Meanwhile most of us are still using our boring old objective truth to examine the world and try to form reasonable arguments.\",\n",
       " 'At the root of these issues ... we\\'ve all noticed an aggressive push for \"social justice\" in the machine learning community. This has been organized by a small number of politically motivated activists who do not represent the community as a whole, outsiders who aren\\'t ML experts themselves. Its impact on the community has been extremely negative. This can be seen in how LeCun was recently silenced on Twitter, or how some people are now claiming [they should get more citations because of their skin color or gender](https://twitter.com/adjiboussodieng/status/1277599545996779521?s=19).',\n",
       " \"Hmm, I came from a chemical engineering background, and it sounds like a lot applies to my research area (nano material) as well. I think it's a general issue for academia, and a lot of it comes from the pressure for publishing papers. When the pressure is on, things like reproducibility and integerity are just out of the window. And when everybody tries to use tricks to get paper published, you'll have to do it too if you want to keep up with the performance, it's a horrible arms race.\",\n",
       " \"First of all, I don't have anything to back up my opinion/impression:\\n\\nAs a european, a lot of these points seem like very American patterns in general to me, more than specifically ML-related issues.\\n\\nThat doesn't make anything you said less true, though.\",\n",
       " 'The final point is very correct. Everybody became insane. It is NOT OK to insult LeCun as if he was a nazi!',\n",
       " \"Yes, a million times of yes. As a junior researcher in this field who is going to start my career as an assistant professor, I am seriously considering quitting research and just go to industry to find a job and work in peace. What is happening right now in the ML community reminds me of what happened in the SU or China in the mid of the last century. This is essentially a kind of silencing -- I don't dare to publicly (say, on Twitter) express my opinion since I know I would easily lose my current job if I do so. Look at Yann, what happened to him in the last few days is astonishing. I understand that there is systematic racism and sexism in this country, but this does NOT mean that everything should be interpreted and explained in this way. Honestly, I feel that some of them are just playing the race/sex card in order to maximize their own utility, e.g., more citations, more visibility etc. What a shame! I never see this happens in maths or theoretical physics. It's a shame that the pursuit of pure research and truth needs to surrender to political correctness.\",\n",
       " \"> Fourthly, the way Yann LeCun talked about biases and fairness topics was insensitive. \\n\\nI understand why you might feel you have to say this, but it isn't true, and catering to that mindset is only going to provide a beachhead for future unreasonable backlashes. People who jumped on LeCun overplayed their hand, but they're still in the community, and will happily jump on other innocent remarks the second we let them think they've got a receptive audience for it. Saying that biased datasets cause problems is not a racist act, there are four lights.\\n\\n> People are becoming afraid to engage in fear of being called a racist or sexist, which in turn reinforces the diversity problem.\\n\\nVery big agree! We need to incentivize outreach and risk-taking.\\n\\n> \\nSecondly, there is a reproducibility crisis. Tuning hyperparameters on the test set seem to be the standard practice nowadays. Papers that do not beat the current state-of-the-art method have a zero chance of getting accepted at a good conference. As a result, hyperparameters get tuned and subtle tricks implemented to observe a gain in performance where there isn't any.\\n\\nDoes anyone have any suggestions on how to avoid this scenario (other than from a conference gatekeeper's perspective)? I've yet to see any. \\n\\nIf Method A is innately more able to get use out of hyperparameter tuning than Method B, then in some sense the only way to get a fair comparison between them is to tune the hyperparameters on both to the utmost limit. Abstaining from hyperparameter tuning seems like it means avoiding comparisons that are fair with respect to likely applications of interest.\",\n",
       " '> It has reached the level of a cult.  \\n  \\nIt was always a cult. It almost feel like it was DESIGNED as a cult.',\n",
       " 'Please make this an open letter that I can sign with my real name.',\n",
       " ' Quite right, for the most part.   \\n\\n\\n1. There\\'s no clear consensus for making papers publicly available while under submission. One one side, it means the research is not available while under review which kind of defeats the whole purpose of research (sharing it with everyone, and not sitting around 2-3 months). On the other hand, sharing it and making posts everywhere does compromise anonymity: even if the reviewers don\\'t search explicitly for the paper, they \\'re highly likely to stumble upon it if their research lies in that area (arXiv update tweets, gs updates, RTs by people they follow, etc). I guess a straightforward solution would be to have a version of arXiv with higher anonymity, where author affiliation is revealed only after decisions (to the journal/conference to which that research is submitted) have been made. We need to think much more about this specific problem.   \\n\\n2. Reproducibility is indeed an issue. I honestly don\\'t know why we\\'re in 2020 and machine learning papers can still get away without providing code/trained models. Evaluating the trained model (which is, in the majority of ML related papers, the result) by the reviewers via an open-source system, perhaps like a test-bed specific for applications? For instance, evaluating the robustness of a model on Imagenet. This, of course, should happen along with making code both compulsory and running it as well. This may be a problem for RL related systems, but this doesn\\'t mean we shouldn\\'t even try doing this for any of the submissions.   \\n\\n3. Very true. For some part, it\\'s the responsibility of organizers to not always run after the top 5-6 names, and include younger researchers to help audiences get familiar with a more diverse (and most times, interesting) set of research and ideas. For the other part, it is also up to the researchers to draw the line when they see themselves talking about the same slides at multiple venues over and over again.   \\n\\n4. This specific instance is somewhat debatable. Compared to the level of backlash and toxicity women and people of color receive online is not even close to what he did. Nonetheless, the discussion could be much cleaner.   \\n\\n5. I agree with the first half. I do see companies doing *something* about this, but surely not enough. Also, it\\'s a bit sad/sketchy that most AI research labs do not openly release statistics about their gender/ethnicity distributions. \"People are becoming afraid to engage in fear of being called a racist or sexist, which in turn reinforces the diversity problem. \" There\\'s a very clear difference between \\'engage\\' and \\'tone-police\\'. As long as you\\'re doing the former, I don\\'t see why you should be \"afraid\".  \\n \\n6. True (but isn\\'t this a problem with nearly every field of science? Countless animals are mutilated and experimented upon in multiple ways for things as frivolous as hair gel) I guess, for instance, people working in NLP could be more careful (or rather, simply avoid) scraping Reddit to help stop the propagation of biases/hate, etc. Major face-recognition providing companies have taken steps to help curb the potential harms of AI, and there is surely scope for more.   \\n\\n7. \" Certain people submit 50+ papers per year to NeurIPS.\" I\\'d think most of such people would only be remotely associated with the actual work. Most students/researchers/advisors I know who work on a research project (either via actually leading it or a substantial amount of advising) have no more than 5-6 NeurIPS submissions a year? Nevertheless, universities should be a little relaxed about such \\'count\\' based rules.   \\n\\n8. \"Everybody is under attack, but nothing is improved. \". It\\'s not like Anandkumar woke up one fine day and said \"you know what? I hate LeCun\". Whatever the researchers in your examples have accused others of, it has been true for the most part. I don\\'t see how calling out someone for sexist behavior by calling them \\'sexist\\' is disrespectful if the person being accused quite visibly is. All of these instances may not directly be tied with research or our work, but it would be greatly ignorant to pretend that we all are just machines working on science, and have no social relations or interactions with anyone. The way you interact with people, the way they interact with you: everything matters. If someone gets called out for sexist behavior and we instantly run to defend such \"tags\" as \"disrespectful\", I don\\'t see how we can solve the problem of representation bias in this community.  \\n\\n\\nAlso, kinda funny that a \\'toxicity\\' related discussion is being started on Reddit. lol',\n",
       " 'Welcome to the new era of science. Everybody is right and nobody is wrong.',\n",
       " 'Hey, really well put.',\n",
       " 'This is really really good. Thank you.',\n",
       " 'Can we improve the peer-review process by scrubbing the authors names and research groups from the paper? Any conflicts of interest issues can be determined by the editor.',\n",
       " 'Is maternity leave really a career ender in your country? Got damn. Where im from, you can’t even ask an employee/applicant in a jobbinterview if they are planning on having children. It is seen as discrimination, and not a valid reason to hire/fire.',\n",
       " 'Thank you for raising those important points! 100% agree 👏',\n",
       " 'I have a different take - the internet (and arguably society as more of it has moved to the internet) has a toxicity problem, but the ML community is not particularly bad.',\n",
       " 'All interesting points , though I really struggle with your mixing of first , secondly .. firstly secondly,  or first second ... \\n\\nSorry, my supervisor kills me for doing it , and now I am hyper sensitive to it ! 😁\\n\\nThat aside, you make some very good  points.',\n",
       " '\\\\>Schmidhuber calls Hinton a thief,\\n\\nNo doubt Hinton is a thief, the whole Toronto communities are thieves and gangsta.Hinton community cross site every stupid articles they write.',\n",
       " 'The good book on the topic that I believe is relevant to this post: [The Coddling of the American Mind: How Good Intentions and ](https://amzn.to/31Sp9UU)  \\n[Bad Ideas Are Setting Up a Generation for Failure](https://amzn.to/31Sp9UU)  \\n\\n\\nMore people will read it during the quarantine - better :)\\n\\n&#x200B;\\n\\n\\\\`\\\\`\\\\`  \\nThe generation now coming of age has been taught three Great Untruths: their feelings are always right; they should avoid pain and discomfort; and they should look for faults in others and not themselves. These three Great Untruths are part of a larger philosophy that sees young people as fragile creatures who must be protected and supervised by adults. But despite the good intentions of the adults who impart them, the Great Untruths are harming kids by teaching them the opposite of ancient wisdom and the opposite of modern psychological findings on grit, growth, and antifragility. The result is rising rates of depression and anxiety, along with endless stories of college campuses torn apart by moralistic divisions and mutual recriminations.  \\n\\n\\nThis is a book about how we got here. First Amendment expert Greg Lukianoff and social psychologist Jonathan Haidt take us on a tour of the social trends stretching back to the 1980s that have produced the confusion and conflict on campus today, including the loss of unsupervised play time and the birth of social media, all during a time of rising political polarization.  \\n\\n\\nThis is a book about how to fix the mess. The culture of “safety” and its intolerance of opposing viewpoints has left many young people anxious and unprepared for adult life, with devastating consequences for them, for their parents, for the companies that will soon hire them, and for a democracy that is already pushed to the brink of violence over its growing political divisions. Lukianoff and Haidt offer a comprehensive set of reforms that will strengthen young people and institutions, allowing us all to reap the benefits of diversity, including viewpoint diversity.  \\n\\n\\nThis is a book for anyone who is confused by what’s happening on college campuses today, or has children, or is concerned about the growing inability of Americans to live and work and cooperate across party lines.  \\n\\\\`\\\\`\\\\`',\n",
       " '[deleted]',\n",
       " 'Well, I found some statements here are actually incorrect or superficial. For example, you cannot simply draw a conclusion based on a single BERT paper without much context, and do not consider a lot of confounding factors (e.g. its results are much better than others). If you just want to reason by a single example, why not look at the two concurrent papers of VAE, [one](https://arxiv.org/abs/1312.6114) from Universiteit van Amsterdam which is cited \\\\~10K times, [the other](https://arxiv.org/abs/1401.4082) from Deepmind which is cited <3K. Can you draw an opposite conclusion from this?',\n",
       " 'Can someone point me towards anyone wanting LeCun to get off twitter? Or to anyone (other than the guy that said \"fuck Yann LeCun\" or something like that) attacking him? To me he overreacted wildly and Timnit didn\\'t quit twitter before being far more harassed by his fanboys',\n",
       " '[deleted]',\n",
       " 'Standard 90/10 split \\n\\n\\n90% Indians watching **MACHINE LEARNING AI SELF TAUGHT ENTERPRENEUR** YouTube videos.\\n\\n10% actually working and studying the field with a technical understand above surface level. \\n\\nAnd it’s no surprise which group is louder and drowns out any actual worthwhile discussions',\n",
       " \"\\\\> Gebru calls LeCun a white supremacist\\n\\nDid that actually occur? I tried to follow but don't recall that o\\\\_O\",\n",
       " 'I think the sixth point you made here is so insanely important and undervalued. I do a fair amount of researching disinformation, in particular deep fakes, and the fact that this kind of technology came from academia without any real thought about the danger it could represent is appalling. Facial recognition and other tracking types of technology fall into this same category. I understand they are cool problems and the machine learning technology behind this is truly amazing, but there has to be some kind of moral check.',\n",
       " 'Thanks for an excellent and needed post. Yes, much of this is in common with academia generally, as many are pointing out. Check out the blog post “Upgrade Your Cargo Cult” by David Chapman for an excellent and uniquely well-informed take on this issue. He discusses how any scientific field is presently marred by bad science, partly because the sciences are mostly going through rote procedural motions while missing the vital other ingredient that makes science work. So instead of science we end up with something more procedural, which marries nicely with market demands — so the result is an overwhelming emphasis on engineering rather than science. ML is a chief example of this. People aren’t left to explore the territory properly because they’re pressured to just engineer useful results with no concern as to how they arrived at such results. It’s a muddling of the research and development ends of the spectrum — a muddling which academia is doing a worse job at managing than it seemed to in the 20th century. Is an ‘ML researcher’ really a researcher or just an engineer with more academic qualification?',\n",
       " '[removed]',\n",
       " \"Couldn't agree more. This desperately needed to be said.\\n\\nEdit: On point  six,David Ha, Joe Redmon and I deeply care about this issue. But, yes, more of the community needs to care about China's abuse of power.\",\n",
       " '- Points 1, 2 and 7: we need open science.\\n- Points 3: ignore the churches and churchgoers.\\n- Point 4: ignore TMZ.\\n- Point 8: ignore twitter.',\n",
       " 'I would suggest the following to solve some of the issues.\\n\\na)Community moderation on arxiv : We have upvotes, downvotes, comments, and ranking by hot, top, controversial on reddit and mods. This to a large extent enables reddit to be a place where you can voice your thoughts but someone can step in if a situation arises. I remember there was this huge backlash on a recent paper that talked about face detection to identify criminal behaviour. The authors were kind enough to retract their submission. Imagine if they had posted it on arxiv, was there anything anyone could have done about it? \\n\\nb)Set guidelines for arxiv: Imagine you get to review a paper but find out that it is from Geoff Hinton, or Yann LeCun.. would you be able to review it in an unbiased fashion? Maybe the authors could upload a blinded submission to arxiv and reveal the names once a) they decide to stop targetting a publication b) the draft gets accepted.\\n\\nc)Make Codes mandatory: The policy of code-release being optional was largely derived from the systems community where releasing the code meant revealing a lot of properiatary IPs (standard-cell libraries cost billions to model, RTL IP licenses were what earned companies money)..however even they have started gravitating towards open-source (if anyone is interested RISCV, tiny compiler by Austin Henley, JOS by MIT are great starting points) however, AI has started to go the other way, fortunately there are voices speaking out against it.\\n\\nd) Make ethics compulsory: There is this famous quote by Oppenheimer after they invented the Atom bomb: \"I am become death, the destroyer of worlds.\" AI researchers need to understand this quote applies a lot to them. \\nThe Atom Bomb killed around 126K people (lowest estimate) in a matter of minutes..Prior to that, if someone had to kill around 126K people, they would need an army that was at least twice that size and would need to fight for at least 20 months (US lost around 6,600 people a month during the war). \\nSimilarly, research that took around months/years can now be done in minutes/days. This is a tremendous amount of power and people who wield it can shape our future. It is thus important to focus on the \"ethics\" of AI rather than look at pure accuracy numbers.\\n\\ne) Better metrics: Increasingly there are models that are able to beat SOTA due to their sheer size. Take BERT for example, Do you think colleges in Africa, Asia would be able to afford the compute costs? How about we rank models based on cost (in terms of power consumed, in terms of money ) and not just based on accuracy?. \\n\\nf) While I might disagree with \"some\" of the language used by Gebru. She has a point. In an increasingly competitive world, if we choose not to stand up for those who do not have a voice, we are choosing to ignore their views and are complicit in silencing them. PhDs are toxic and cutthroat and AI research is even more so. My girlfriend was forced to walk out of a project for speaking out against harassment because the harasser was \"intelligent\". If people like Gebru are silenced, people like my girlfriend are the ones who will have to pay the price. I would highly recommend watching the documentary called \"disclosure\" on netflix to understand the consequences of ignoring someone\\'s perspective. If Gebru hadn\\'t spoken out against racism and the danger of facial recognition algorithms, we would still be having companies like clearview.ai mining our data for surveillance. \\n\\ng) Understand privilege: This is something ALL AI (and Security) researchers need to understand. If you are a researcher publishing one or two papers in AI (or Security), you have some degree of privilege. Think about what you need to know to be a decent AI researcher today: A fair deal of programming, linear algebra, probability, good vocabulary, free time to keep up with deluge of papers in your field, a good peer group to discuss and brainstorm ideas, and finally resources to conduct experiments. ALL of this is privilege. So when someone is trying to point out an issue, maybe we can listen.. and yes, sometimes the issue may not be presented correctly or the person might use language that we cannot stomach. But the question we must ask ourselves is \"What are we losing by just listening to the other person?\".',\n",
       " '[deleted]',\n",
       " 'Hit so many nails on the head it sounded like a jack hammer.',\n",
       " \"I've been reading so many insane things on the internet today. Your post made the tension in my belly finally relax.  I like you.\",\n",
       " 'I appreciate the directness of your points and I shall try (and, inevitably, fail) to emulate that in my response:\\n\\n> **First** of all, the peer-review process is *broken*.  \\n\\nIt\\'s the peer review system that is broken, it\\'s just a disconnect between the traditional methods for publishing work and the way people actually share ideas and results. Traditional publishing is dead - it has been since the internet, and the final nail in the coffin was social media. Unfortunately, most of academic science has yet to move towards a good alternative. arXiv is one such glimmer on the horizon - instead of going through a slow month or year long process to share your ideas and findings - just self publish and truly allow your work to be judged by your peers (all of them). If it\\'s true only a fourth of NeuIPS submissions are uploaded to arXiv then I am sad it\\'s not far more. \\n\\nWe need to integrate the countless new mediums of communication and visualization into how we share science. So far, it\\'s mostly the large companies (OpenAI, Deepmind, etc) that present their work with blog posts including multimedia and even interactive visualizations. Instead of condensing everything down to an eight page static paper - we should be encouraging submissions of full multimedia websites - ideally built on a common framework to make powerful visualization tools available to everyone, automatically generate printable versions for the old timers, to enable reviewers to respond/discuss directly on the page (a la OpenReviews) and, if accepted, to base the acceptance on the submission hash to identify tampering and recognize later changes). I am not advocating eliminating the peer-review system, I want make the whole process as transparent and dynamic as possible, and integrate the newest tools and media available.\\n\\n> **Secondly,** there is a *reproducibility crisis* \\n\\nI agree, that\\'s why we need a fundamentally new publishing platform where we can integrate/share code, data, and models directly (rather than occasionally linking to a disparate github repo). Ideally, the framework would have some compute behind it (maybe like Google Colab) so that all the models and code submitted can be run directly in the conference/journal submission page - imagine that: reviewers being able to interactively test people\\'s models rather than going off of nothing but cherry-picked samples.\\n\\n> **Thirdly,** there is a *worshiping* problem. \\n\\nThat\\'s probably true, although I can\\'t speak too much about it, as I\\'m not very involved in the politics of academic research. That being said, all enterprises will inevitably involve some icky politics and favoritism. The best we can do to combat that is make things as transparent as possible.\\n\\n> **Fourthly**, ... *toxicity*\\n\\n This problem goes far being ML/AI research - it has pretty much pervaded throughout all of public discourse at this point. We can discuss the problem of \"toxicity\" in general, which I would chalk up to our culture having not quite come to terms with the fundamentally different way we have to process information in the information age. However, overall I think AI research (and science in general) does a better job than most areas on that front.\\n\\n> **Fifthly**, ... a huge *diversity problem* \\n\\nI completely agree, and there are plenty of arguments for why we and all of academia has a diversity problem. You are probably familiar with most, and we don\\'t have to get into them, but suffice to say, once again, our cultural and traditional biases and institutions conflict with a more contemporary mentality. What do we do about it? Outreach and transparency - they are slow but they work.\\n\\n> **Sixthly**, moral and ethics are set *arbitrarily* \\n\\nThe problem here is a little unclear to me? Is it that people use technology in ways other people don\\'t like? That seems inevitable. Is it that Western culture undervalues the rest of the world? What else is new? Don\\'t get dragged down with the American Exceptionalists in denial as the US heads for economic and social stagnation and decline.\\n\\n> **Seventhly**, there is a cut-throat publish-or-perish *mentality*.  \\n\\nComing from physics research, I agree that the AI field has a dangerously strong publish-or-perish mentality. However, that also means the field is highly dynamic and garners lots of interest/funding. I\\'m not convinced that a field as closely intertwined with engineering and the private sector does not actually benefit from a shorter project cycle. Additionally, the barrier to entry is virtually non-existent (unlike most other sciences where researchers won\\'t give you the time of day if you don\\'t already have a PhD, and the equipment/expertise necessary for making progress precludes anyone outside of 2-3 groups on Earth from publishing on your topic).\\n\\n> **Finally**, discussions have become *disrespectful*. \\n\\nAgain, that\\'s really just a misunderstanding for the way information works in the information age. Attention is a commodity and insulting people still has a high rate of return. This will change for the better as we get a handle on how to process information in this brave new world (especially in informal settings like social media).\\n\\nThanks for the points though - it does us well to think critically about not just the \"what\" in research but also the \"how\" and \"why\".',\n",
       " 'Good points about ecerything except the racial diversity qouta',\n",
       " \"Calm down, young one, too much drama ;)\\n\\nA lot has changed over the past ~5 years, and the machine learning field really raised the bar on standards imho.\\n\\nPapers are no longer behind a paywall? And there's code to go with it and results can be reproduced? And open datasets to benchmark against? Ya kidding me? 10 years ago if you took latest state of the art paper and implemented it yourself, you'd find out your performance is somehow worse. That maybe some magic values were not mentioned. Or they hand-picked test sequences. Etc.\\n\\nPeople worship Google or Stanford? Few years back, the fashion was about publishing in Nature and Science and chasing impact factors. Either way, exceptional work gets recognized, that's the best you can do anyway. Get published on merit.\\n\\nSo, worried about publishing by all means, marginally pushing the envelope on state of the art and mostly just tinkering with hyper parameters until you get the result you wanted? That's just what academia has been about the past 40 years. It's an issue worth addressing, sure, but it is  not recent and not unique to any given field.\\n\\nAs for the rest.. about sexism, biased datasets, Twitter scandals or democratizing AI.. That's just the scandal of the day. In the end, opinions are like farts.. everyone has them, but maybe it's better to keep it to yourself.\",\n",
       " 'This post is a grab-bag of unrelated, tired (even if valid) complaints about the field.\\n\\n>First of all, the peer-review process is broken.\\n\\nFirst of all, what does this have to do with toxicity? \\n\\n>Every fourth NeurIPS submission is put on arXiv. \\n\\nThe fact that papers are going up on arXiv is a good thing. The fact that peer-review suffers as a result is bad, and it has been raised and discussed many times but no one yet has a solution. The fact is that we don\\'t currently have a system that both allows for fast dissemination of research and a blind review process. That it has not been fixed is not for the lack of attention or trying.\\n\\n>Secondly, there is a reproducibility crisis.\\n\\nSecondly, what does this have to do with toxicity? \\n\\n>Papers that do not beat the current state-of-the-art method have a zero chance of getting accepted at a good conference.\\n\\nThis is patently false, and one of many instances of hyperbole in this post.\\n\\nPeople have been discussing a \"reproducability crisis\" in ML, but... where is it? The BERT-class models in ML have been consistently reproduced. To my knowledge the best vision models have similarly had their results reproduced too. Where there\\'s an unreproducable result, it\\'s either been called out and the author responds, or without a response it\\'s taken as an unreproducable result that\\'s ignored. The biggest reproducability problem has to do with access to data and computational resources, but that\\'s by no means the same \"reproducability crisis\" in other fields.\\n\\n>Thirdly, there is a worshiping problem. Every paper with a Stanford or DeepMind affiliation gets praised like a breakthrough.\\n\\nMore hyperbole.\\n\\n>BERT has seven times more citations than ULMfit\\n\\nIt also performs a lot better than ULMFiT. I say this as someone who thinks ULMFiT doesn\\'t get enough spotlight in the LM->encoder sphere. ELMo also basically disappeared overnight because of BERT.\\n\\n>Next, Bengio, Hinton, and LeCun are truly deep learning pioneers but calling them the \"godfathers\" of AI is insane. It has reached the level of a cult.\\n\\nCan you explain, in concrete terms, how using an analogy of \"godfather\" (which I take in the meaning of a founding leading, rather than from the mafia) is \"insane\" and \"has reached the level of a cult\"? Or is that just hyperbole?\\n\\n>Fourthly, the way Yann LeCun talked about biases and fairness topics was insensitive. However, the toxicity and backlash that he received are beyond any reasonable quantity.\\n\\nThis is the first actual mention of toxicity, and very obviously the trigger for you to rant about the field.\\n\\n>Fifthly, machine learning, and computer science in general, have a huge diversity problem. \\n\\nLet may state this first, and upfront, that while this problem is not unique to ML and CS, it is still an important problem that needs to be addressed. That said, it has nothing to do with toxicity (or specifically, not in the way you\\'re talking about. You\\'re not, for example, talking about how toxicity makes ML less diverse, you\\'re in fact arguing the opposite) and it sounds like just another point to pad out your list of complaints, until:\\n\\n>this lack of diversity is often abused as an excuse to shield certain people from any form of criticism. Reducing every negative comment in a scientific discussion to race and gender creates a toxic environment. People are becoming afraid to engage in fear of being called a racist or sexist, which in turn reinforces the diversity problem.\\n\\nI have no idea what on earth you are talking about, or where you are getting into these sort of discussions.\\n\\n>Sixthly, moral and ethics are set arbitrarily. The U.S. domestic politics dominate every discussion. At this very moment, thousands of Uyghurs are put into concentration camps based on computer vision algorithms invented by this community, and nobody seems even remotely to care. \\n\\nYou\\'ve just described... the Internet in general. Look at the front page of Reddit: it is just as dominated by US politics. Same for Twitter trending. \\n\\n>Seventhly, there is a cut-throat publish-or-perish mentality. If you don\\'t publish 5+ NeurIPS/ICML papers per year, you are a looser.\\n\\nI have never seen someone publicly called a loser for not publishing sufficiently. I\\'m sure it\\'s happened in specific groups, but it is not generally considered acceptable by the community. That\\'s even putting aside the hyperbole of \"publish 5+ NeurIPS/ICML papers per year\".\\n\\nAlso, what does this have to do with toxicity?\\n\\n>Finally, discussions have become disrespectful. ... Gebru calls LeCun a white supremacist\\n\\nGebru never called LeCun a white supremacist. Did you distort what she said for the purpose of fanning flames of an argument? Is that the not clearest possible example of \"toxicity\" you are arguing against?\\n\\n----\\n\\nThe field is not without its problems, for sure. There are many issues of accessibility, diversity, and dissemination of information that need to be addressed. Most of it has to do with how quickly the field has grown, and the institutions and even social conventions that have not yet adjusted to accommodate its new size and prominence (too many qualified students, too many papers, too many new results). A related part of it is the potential misuse of the technology that we\\'re building and researching. And for all the negativity and online arguments that have gotten of hand, one of the best parts of the field is that a lot of this is done in public, with free communication, and a lot of genuine self-criticism. Ask almost anyone in the field and they would agree that we are not doing enough to address all of these problems, even if we don\\'t yet agree on how we can do better.\\n\\nPosting a big list of unrelated, hyperbolic complaints stemming from cherry-picked examples (How many labs have PIs who don\\'t know all their PhD students? How often do researchers publicly go after their reviewers?) for the purpose of stirring up a big flamey debate, does nothing to help. You\\'re picking out the worst possible examples to [mischaracterize the field and the community](https://www.reddit.com/r/MachineLearning/comments/hiv3vf/d_the_machine_learning_community_has_a_toxicity/fwiikfx/). If you wanted to have an actual discussion on toxicity, you would have focused on that rather than include a load of unrelated points to make your big rant.\\n\\nSigning off your message with \"Best intentions\" does not excuse the rest of your post. Based on your post history I think you do have good intentions but this post is absolutely not productive.',\n",
       " \"> Thirdly, there is a worshiping problem.\\n\\ni agree about the godfathers portion.\\n\\nhowever the worship of publications from places like Google or DeepMind is unfortunately very well-founded.\\n\\nif you look at most university papers, they are training over 1/100th the amount of data industry papers use (for good reason).  as a practitioner it just isn't worth your time to look for other papers unless you're chasing the last few basis points.\",\n",
       " 'I used to write \"j\\'accuse\" shit like that, then decided to lower my sodium intake',\n",
       " 'I love the cliques that can form in certain fields in academia. It’s like extremely smart people that never left their high school personality behind. Main reason why I left: I couldn’t take being called an idiot and my research trash for nothing other than my institutional affiliation and my PI. Forget that shit.',\n",
       " 'I’m sorry but you have now transgressed against the Twitter clique so I’d expect quite a bit of pushback on some of these points from them. \\n\\nOnce the counter pushback begins that will then be considered harassment and this thread will be binned. 3..2..1...',\n",
       " \"Why is it that you are upset that your politics are not being spoken about?\\n\\nIt's machine learning not political science.\\n\\nI think your points have the same smell as the part you said about demonizing those who do not share other's views. \\n\\nImagine me being a trump supporter in the ML community.. Its the same thing man we are all just being silenced; so we can focus on the science.\",\n",
       " 'Anything we’re doing right?',\n",
       " 'Just chiming in, I totally disagree with everything said here.\\n\\n1. Peer review is not broken, it’s just stupid. Move the conferences to invite-only and get rid of the proceedings. ArXiv is fine for publishing.\\n2. Only if you care about these sorts of papers. Most papers that aren’t just incremental nonsense still have robust theory.\\n3. Hero-worship gives researchers something to aspire to and is a good thing.\\n4. LeCun did nothing wrong. In fact, the particular instances isn’t even a good case of ML bias because it just shows the model prediction failing embarrassingly badly. Fixing it requires conventional improvements, not “fairer” datasets and certainly not engineers with a different skin color.\\n5. Women are prejudiced against ML. That’s their bigotry, not ML’s.\\n6. Yes, the officially sanctioned research of the American Empire is excessively focused on the Empire. Why do you think the Emperor pays you?\\n7. I will agree with you on this point.',\n",
       " '>People are becoming afraid to engage in fear of being called a racist  or sexist, which in turn reinforces the diversity problem.  \\n>  \\n>Gebru calls LeCun a white supremacist\\n\\nCertainly you\\'d agree that misrepresenting an interlocutor\\'s arguments falls pretty squarely in the disrespect category? It\\'s part of why minorities are afraid to speak up about such issues, thus fueling the diversity crisis. There\\'s a common perception that those who talk about racism/sexism receive acclaim and support from those in power. This has not been my experience (nor for anyone else I know). There is very little to gain from speaking up aside from the hope that the other person will treat others better in the future. In terms of what the speaker loses, well, she\\'s already had her words misrepresented, and now runs the risk of being labeled \"aggressive\" and \"hard to work with\" in the backroom conversations that we all know run academia and industry alike.',\n",
       " 'Are you not contributing to the problem? Many of the threads you started on this subreddit just report on big names, rumors and other shit-stirring. Your points are not even exclusive to machine learning anyway, and could just as well apply to any other area of academia.',\n",
       " '> Albert Einstein was opposing the theory of quantum mechanics\\n\\nHow is this salient?',\n",
       " 'I agree with some of your points. But this part:\\n\\n“**Sixthly**, moral and ethics are set *arbitrarily*. The U.S. domestic politics dominate every discussion. At this very moment, thousands of Uyghurs are put into concentration camps based on computer vision algorithms invented by this community, and nobody seems even remotely to care. “\\n\\nSeriously? So you want this community to stay out of the ongoing BLM stuff and at the same time Uyghurs is the politics that we are supposed to talk about? Aren’t you having double standards here?',\n",
       " \"I have no idea how to solve most of these. And yeah, a lot of the social problems are really fucking bad. But I made a post a bit ago on an idea that I had for a new journal, as an experiment to try and solve some of the issues with reproducibility and name recognition worship. It'd be a whole thing to set up, but if I got some support from folks here, I'd be willing to go through with it.\\n\\nI love Machine Learning. I love the theory and the applications. And a lot of the people are really cool. I want to do what is in my limited power to help.\",\n",
       " 'I grew up wanting to be a scientist but became disillusioned by the idea when it became clear that the problems you mentioned were ubiquitous in modern science.',\n",
       " 'Most of these points apply to research in any other field as well (just replace some names) and it’s outrageous!',\n",
       " \"I'm bored while waiting for a job. If anyone has a paper they would like me to try to reproduce, please send it to me and I'll give it a shot.\",\n",
       " 'This sounds like Academia in general and nowadays Society even more generally. I mean, look at how aggressive people are even here on Reddit with perfect strangers they disagree with for all sort of petty matters. Most people are tribalized, frustrated, echo-chambered and do not know how to debate rationally without starting to insult or demonize others.',\n",
       " 'Agree. I think this happens anywhere. Outside of academia, there are some ways to control bad things. Do you have any suggestions on how to resolve? Realistically. Maybe one must be content to proceed a small step at a time. But a precise and detailed proposal is needed.',\n",
       " \"About the space taken by large companies (your third point), I have to say that in my personal experience I've moved in just few years from models I could easily train on even my laptop to models that need a big infrastructure. And since I'm not in a big player team, I have to wait for my experiments in the queue of some shared supercomputer. This is deepening the gap between the research carried out at public structures and the private large companies.\",\n",
       " 'Indeed, it also happens in computer vision.',\n",
       " \"Thing is there is lots of half knowledge revolved around machine learning. I include myself to it but always try to respectfully make claims or ask questions. Everyone is a data scientist these days simply because it is so overhyped. And there's lots of narcisissm and envy from both experts and beginners. I'd say this contributes a lot to this toxicity.\",\n",
       " \"I come from IT and the culture of worshipping is really funny and not going to last. You're not all Einsteins, you're building on the great work as a group, hiding good work to protect discrete innovations is silly and people should be satisfied to be lucky enough to participate in an amazing day and age. I'm excited about the possibility of working with more diverse researchers too.\",\n",
       " 'There is only one (two) problem with the so-called AI: a lot of money (power).',\n",
       " 'Wow where can i read more about the reproducibility crisis? Do authors later and come out and admit that they overfit to the test set or anything ?!?!?!',\n",
       " 'Tuning HPs on test set is a standard practice now: when did this happen? Am I missing something?',\n",
       " 'Can anyone send a journal paper example showing that \"Tuning hyperparameters on the test set seem to be the standard practice nowadays. \"?',\n",
       " 'One explanation of the “BERT” issue mentioned above is that we all know how popular something is and there is an avalanche effect.\\n\\nIf we didn’t have this information, and consumed research by reading a journal issue whose papers had varying levels of citations we might be more likely to discover diamonds in the rough. Kind of along the same lines as the problem of social media feeds as echo chambers.',\n",
       " 'not much more to say other than:\\n\\nCarpe Jugulum',\n",
       " \"And above all.. everybody knows that doesn't work\",\n",
       " 'Just like Reddit.',\n",
       " 'All of your points are valid and this belongingness to anything top-notch and premiere has been very toxic for me. I am right now in an okayish college but I am eager to work with top research labs in my country. Apart from bigger personality cults, researchers who have accomplished something slightly good also have their own mini-cults which is very hard to cross barrier for students like me.',\n",
       " 'One point not mentioned much in your list: how bad is plagiarism in ML/DL? Are there any movements/organisations to prevent/resolve issues related to this?',\n",
       " 'And unfortunately some Data Science teams inherit that toxicity.\\n\\nHere are some some elements that can help:\\n\\n* place everyone on the same level\\n* promote diversity\\n* reward inclusivity and support between teammates',\n",
       " 'There  is a huge toxicity problem in the field indeed -- credit assignment is  at the top of the list (and I am not talking about the credit assignment  problem in artificial neural networks...).\\n\\nAs  a scientist/researcher/professor in the field myself, I have witnessed a wide  variety of issues ranging from the unethical rejection of  papers from  conferences such as NIPS/ICML and the very broken ICLR to the  exploitation of \"noise in the review system\", where researchers just  keep submitting the same paper across conferences until they sample the  right set of reviewers who will accept their paper, to plagiarism (and  more commonly, \"idea plagiarism\").(With respect to ICLR, the  concepts behind OpenReview are good in theory, and I understand its  ideals, but it is implemented poorly in practice, in my opinion.  Ultimately, this creates what I call the \"wall of shame\" for papers that  have been rejected, making it difficult for graduate students and  researchers to overcome the bad reviews received -- and this is made  worse b/c the reviewers are kept anonymous and thus not held accountable  to their poor reviews).\\n\\nUltimately,  what has been created in the field in many ways is what I have called  for many years the \"deep learning rat race\", where accomplishments are  often just outperforming a benchmark by a percentage point or two.   Furthermore, the review process is not being held to higher standards  (often attributed to the increasing deluge of submissions that place a  tremendous burden on reviewers and conference staff), leading to  situations where some actually reject a paper and then \"copy\" the idea  for themselves (with no citation at minimum -- again, the \"credit  assignment\" problem as noted above) in their own work (and if the copier  comes from a prestigious lab, the original source/proposer gets  overshadowed since they do not have the prestige of name that comes with  Stanford or Mila, for example).\\n\\nI  could go on further and add plenty of details and \"war stories\" to  accompany some of the issues I have raised above (and this does not even  address the many other problems pointed out in the OP\\'s post). But, in  essence, I think that what the machine learning community, at large, really needs is a drastic \"culture change\" across all levels (ranging from the  newcomers to the famous/established) addressing problems that plague the  field such as \"publish or perish\" and \"idea plagiarism\" (prominent in  the famous/big labs especially) as well as reviewing quality in  conferences.I often find much better reviewing (in general, there  are exceptions) in journals as opposed to conferences, where at least  the researcher is given reasonable and useful constructive feedback that  can be used to improve the paper and address issues in the work (if  they are addressable). Conferences have, especially recently, become a  disappointment for me, more than usual, given that the reviewers will  not even read the rebuttals me and my students carefully craft to abide  by the very strong constraints on word/character limits while still  addressing issues from reviewers that are actually address clearly in  the very text of the paper (of course, this assumes reviewers read the  whole paper -- which is unlikely, given that so their plate is quite  full with many, many reviews overall). Until we induce a deep cultural  shift in the field of machine learning and truly address its \"old boys\\'  club\" like scheme (where only those coming from the prestige get their  work recognized), the field will only progress more slowly.\\n\\nI  will mention though (for fellow professors that share my silent agony),  that part of this change comes from within our own labs. While it is slow  and more challenging to change our institutions, instilling a strong and  healthy culture and set of practices in one\\'s own lab is key to  inducing the cultural shift I wish would happen across the field  globally. If you hold your students to rigor and credit assignment,  build lab comradery (starting by knowing the names of your students, at  the very minimum) and supporting your students whenever you face often  cruel and unethical rejections, and never let your own work slip due to  the many frustrations and issues from the field, I believe your lab can  contribute to a brighter future.',\n",
       " 'Re your final point: my opinion is that discrimination is indeed disrespectful. Your 5th and 6th points even mentioned that there is a huge ethics and morality problem in ML research, that certain groups of people are left out. Meanwhile calling out someone who hold discriminative views is important such that people are aware of these toxic opinions. That said accusing someone of being a thief is bizarre, but white supremacy, racism, and sexism are problems that research community indeed should consider themselves to fight against.',\n",
       " \"I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:\\n\\n- [/r/hackernews] [The machine learning community has a toxicity problem](https://www.reddit.com/r/hackernews/comments/hm96uf/the_machine_learning_community_has_a_toxicity/)\\n\\n- [/r/patient_hackernews] [The machine learning community has a toxicity problem](https://www.reddit.com/r/patient_hackernews/comments/hm9d23/the_machine_learning_community_has_a_toxicity/)\\n\\n&nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\\\\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*\",\n",
       " 'This kind of \"science\" is imho for the classic Academical research field.\\n\\nBut this is now in the process to die. Regarding AI, most of research is done in the IT industry. Nothing the old, obsoleted and often pretentious Academic planet knows...',\n",
       " \"Re-hashing old work and claiming it as new by re-naming. 90% of the authors don't even do the literature survey right, what is the point of having 100s of people on your team?\",\n",
       " 'Great post',\n",
       " \"Wow I'm fucking glad someone wrote on this issue. I just want to point out how it extends in all its ugliness to NLP publications (especially now thanks to BERT). NLP is now getting fuller and fuller with people who do not know linguistics or langauge and do not want to work on those skills whatsoever because they don't matter, and who instead simply make models that push the state-of-the-art up a notch and get published. This abuse is extremely facilitated by newly emerging ML methods. People have even gotten into the habit of hiding and shielding their codes from others who want to use or develop the code or replicate results. \\n\\nAnd many avoid talking about this because apparently bringing it up is 'toxic' but a blind eye is turned toward those who actually do this. \\n\\nI am incredibly sad to be in a field where I have to rush to learn patch-up skills in boot-camp style and compete on numbers rather than quality of results.\",\n",
       " 'Wow! Hitting the nail on the head! Absolutely agree.',\n",
       " 'Sounds like....every academic field ever.',\n",
       " '[deleted]',\n",
       " '>However, this lack of diversity is often abused as an excuse to shield certain people from any form of criticism. Reducing every negative comment in a scientific discussion to race and gender creates a toxic environment. People are becoming afraid to engage in fear of being called a racist or sexist, which in turn reinforces the diversity problem.\\n\\nIt is not minorities and others responsibility to put you or your worldview at ease when deciding to call an act racist, because racism is alive and real as plenty of people have witnessed nationwide.   It is only important to discern if their comment is *invalid* or *valid*.\\n\\nIronically you say:\\n\\n>The moment we start silencing people because of their opinion is the moment scientific and societal progress dies.\\n\\nYet it seems like in arguing for \"best intentions\" what you are advocating for them *is* silence.',\n",
       " \"I'm working on technology that will ensure that marginalized and under-represented members of the public will appear equally often in any context. I can't get into all the details, but basically it involves taking percents like 0.05 and multiplying them by 10 to get 0.50 or fifty percent. That gives us equality. ;)\",\n",
       " 'If Gebru sees racism and Anandkumar sees sexism, are those not opinions they should be able to discuss? Do they deserve to be silenced because their opinions are not acceptable?',\n",
       " 'Well stated. But i dont see anything that will drive meaningful change. \\n\\n\\nIt does sound like folks at deepmind and stanford are the best place to start lobbying, though.',\n",
       " 'Some of these observations are applicable to academic research as a whole, it is not just in ML/CS.',\n",
       " 'take my 🏅',\n",
       " \"I'm gonna sound super elitist. But sadly all that you describe is par for the course whenever a discipline expands beyond the breaking point of easy availability.\",\n",
       " \"This is a good post and you're right, but there's one criticism I have:\\n\\n>**Sixthly**, moral and ethics are set *arbitrarily* ... At this very moment, thousands of Uyghurs are put into concentration camps based on computer vision algorithms invented by this community, and nobody seems even remotely to care.\\n\\nThe way I see things, there is no such thing as evil knowledge. It's all just knowledge. The techniques, in a way, are there to be discovered whether we explore them or not.\\n\\nWhat's happening in China is horrifying and I'm sure a lot of us care. I just think you have to aim your ire in the right direction, though, which is at the people doing evil things with that knowledge, not the people uncovering the knowledge.\",\n",
       " 'Nothing from preventing you from creating your own far more accessible and more openly governed peer review journal except laziness.\\n\\nThe issues with institutions that run conferences and journals may be real, yet for some reason the broader \"academic\" community around many topics not just ML would rather complain and continue to pedestool institutions and select people rather than actually pool communities together and build your new forms of more resilient and democratized credability.\\n\\nYou\\'re also conflating your point by going off on politically correct tangents concerning workforce demographics with assinine assumptions. \"Going on parental leave during a PhD or post-doc usually means the end of an academic career\".. uhm what? Do some research before you just repeat talking points. Edward Witten took quite a few years in an entirely different field before becoming one of the most signifigant theoretical physicists quite later. The reality is that woman prefer holistic lives generally and on average personality wise would rather live with more balance than sacrifice tremendously for narrow achievement in science. It\\'s also true that men don\\'t do enough generally to help raise their kids, so that number may well be slightly less skewed in time, but this number is always gong to be skewed so long as signifigant biological differences between sexes. \\n\\nI don\\'t know how reddit is so retarded that a thread like this shoots up into outerspace upvote territory with so little substance or useful insight.',\n",
       " 'Totally agree! Paper acceptance has more to do with affiliation than anything else, and the quality has dropped significantly. \\n\\nThe stuff coming out of FAIR has been garbage for years. (I haven’t seen as many deepmind papers I was critical about.)\\n\\nWhen are we going to admit we have a naked emperor on our hands and start dealing with it?',\n",
       " ' This article details the package and includes links to the GitHub Repo & Tutorial Notebook: [https://mikaelalafriz.medium.com/introducing-lucid-sonic-dreams-sync-gan-art-to-music-with-a-few-lines-of-python-code-b04f88722de1](https://mikaelalafriz.medium.com/introducing-lucid-sonic-dreams-sync-gan-art-to-music-with-a-few-lines-of-python-code-b04f88722de1)\\n\\nYou can support me through PayPal if you like my work: [https://www.paypal.com/paypalme/lucidsonicdreams](https://www.paypal.com/paypalme/lucidsonicdreams)',\n",
       " 'This whole thread is 🔥',\n",
       " 'That microdose is finally starting to kick...',\n",
       " \"YES! I've been waiting on this since the original post, and even sent so far as to start curating my own set to train on.  I can't wait to read your code to see how this is done; I think I know but not positive.\\n\\nedit: I don't suppose there's a Pytorch version is there? Curious why you chose the TF implementation when the Pytorch one is more efficient.\",\n",
       " \"OMG, I think this is the best use of GANs I've ever seen. I'll definitely give it a try !  \\nAlso, what's the song playing in this video ? :)\",\n",
       " \"I'll have what the computer's having!\",\n",
       " '[deleted]',\n",
       " 'Thank you so much for sharing this. I\\'d love to try it out on a song I made however when I substitute the file path for my file path I keep getting error not found raised. this is the file path i insert after \"song = \":\\n\\n/Users/username/Downloads/song.mp3\\n\\nsorry I know ur not like stack exchange or something but if i could get some help i would be super grateful',\n",
       " \"If your system is >= python3.8, it won't work as this library imports TF 1.15 and python3.8 only supports TF2. No luck.\",\n",
       " 'This is great! Would you mind sharing what dataset the GAN from this demo was trained on?',\n",
       " 'Where can I get the winamp plugin?',\n",
       " 'I notice there is almost a constant shape in each frame that persist for nearly the whole video',\n",
       " 'This is awesome, hoping to give it a try. Running into an error:\\n\\n\"Conv2DCustomBackpropInputOp only supports NHWC\"\\n\\nI think it\\'s trying to use my CPU instead of GPU... anyone have ideas?',\n",
       " '\"What have you been feeding this thing?\"',\n",
       " 'This looks fantastic!! Very excited to give this a try later',\n",
       " 'Would this work on amd gpus as well? or is it nvidia only?',\n",
       " 'Amazing project!!\\n\\nI am wondering how is this different from [Deep Music Visualizer](https://github.com/msieg/deep-music-visualizer)?',\n",
       " \"[here's my attempt with the 'modern art' GAN and Miles Davis' My Funny Valentine](https://drive.google.com/file/d/18G7WnGdRfkvDagHMLUltJXG5SqNggBjG/view?usp=sharing)\",\n",
       " 'This is awesome thank you! So easy to install and use.',\n",
       " 'dnnlib ModuleNotFound Error???\\n\\nTryna use with Conda venv to use 1.15 tf',\n",
       " 'This is clearly not for tripophobic people.',\n",
       " \"I hate and at the same time love that you feel like you can just about make out what the object or scene depicted is, yet after a moment or two you realize that whatever you've seen wasn't there, like a mirage.\",\n",
       " \"I don't understand but the pictures are pretty and they move with the music.\",\n",
       " 'This is surprisingly good, makes a really good visual for that track honestly. Nice job',\n",
       " 'This is so dope...thanks for sharing...',\n",
       " \"First and foremost - thank you very much fore being so generous to share this and license it under MIT!\\n\\nNow, considering that on the Github page it says\\n\\n>By default, it uses NVLabs StyleGAN2, with pre-trained models lifted from Justin Pinkney's consolidated repository. Custom weights and other GAN architectures can be used as well\\n\\n, does that mean that any generated material cannot be monetized on YouTube or such, since Nvidia Source Code License-NC claims that any derivative work may not be used for commercial purposes?\\n\\nAnd if so, are there any pretrained alternatives?\\n\\nI'd really appreciate the answer! :)\",\n",
       " 'Just wow, thanks for sharing this.',\n",
       " 'What music is that? Sounds nice !',\n",
       " 'I feel like you just injected something into my brain.',\n",
       " 'Nft potential?',\n",
       " 'Still incredibly cool',\n",
       " 'This is so trippy. Love it. Great stuff OP!.',\n",
       " 'Wow',\n",
       " 'Very nicely done - congratulations. Do you know if this would be difficult to integrate with a chrome cast ?',\n",
       " 'Wow this is nuts I need to ttry this out!',\n",
       " 'Super cool stuff!',\n",
       " 'Duuuude, this is brilliant! Thanks for sharing it!!!',\n",
       " 'This is how Araki create Stands.',\n",
       " \"How does this work in terms of being allowed to use/edit what's generated? Any sort of licensing/ownership issues?\",\n",
       " 'Wow! Is there a way to do it with Rstudio? I will love to use this with my own productions 🙌🏼 https://soundcloud.app.goo.gl/KVv85pidXmtFAYk4A',\n",
       " 'This is surprisingly cool, but I feel it would be even cooler if it actually synchronized with the beat rather than the sound energy.',\n",
       " 'Neuro ASMR, love it!',\n",
       " \"My friend has a band with a few songs and I think it would be a cool surprise to use one of their songs with this package. Just wanted to ask how would you like to be credited for the work. The band is super small and if they wanted to put it as a youtube video I don't think they would monetize it but I'd still want them to somehow credit you.\\n\\nJust hypothetically if they were to like the outcome or I can of course just give them the surprise and say the author isn't open to people sharing their own videos with the package if that's the case also. \\n\\n&#x200B;\\n\\nReally awesome work though!!\",\n",
       " 'Amazing project!',\n",
       " 'this is so cool, thx for sharing and NICE WORK!',\n",
       " \"This is the coolest thing I've ever witnessed. I need to learn everything and anything about this. Thank you kind soul for sharing this work\",\n",
       " 'Well this is just the tits!',\n",
       " 'Kind of ignorant question, would this be possible to run on streaming audio? \\n\\nI’ve been doing DJ streams since the pandemic started and always looking for interesting visuals. I’m also a Junior data scientist and the possibility of setting up a live-generated visual system is super intriguing. Don’t know if it’s possible, though, or what kind of lag it might have if it were.',\n",
       " 'The word \"lucid\" doesn\\'t mean anything here, right? \"Lurid\" might work...',\n",
       " 'Very interesting project! Can one specify a batch of images to be used? Or are the images randomly picked from a preselected batch?',\n",
       " 'No',\n",
       " \"This is so cool! Amazing work, can't wait to try it!\",\n",
       " 'Now I want to be someone who is able to create music and also someone who knows how to train GANs, so I can make one of these',\n",
       " \"You've done a really good job of this!\",\n",
       " \"'ukiyo-e\\xa0faces' style works great for drum & bass music. Would be great to automate a stream from a playlist, i.e. processing the next song while one video is already playing\",\n",
       " \"ahhhh you beat me to it, this has been a project I've been wanting to do to teach myself more deep learning and GANs, looks amazing. I still have another GAN project idea that hopefully I can work on and you won't finish before me haha.\",\n",
       " 'Personally, I would have called this DeepDrag instead.\\n\\n(amazing work)',\n",
       " 'Looks like a dmt trip',\n",
       " 'anyone able to get such an old tensorflow? \\n\\n    ERROR: Could not find a version that satisfies the requirement \\n    tensorflow==1.15 (from lucidsonicdreams) (from versions:\\n     2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1)\\n    ERROR: No matching distribution found for tensorflow==1.15 (from lucidsonicdreams)',\n",
       " 'It’s awesome!!! Is it possible to make it usable for live performances?',\n",
       " 'u/SaveVideo',\n",
       " 'u/savevideo',\n",
       " '[deleted]',\n",
       " 'This is incredible.',\n",
       " \"And here I thought WinAmp visualizations really kicked the llama's ass... this explodes the llama into radioactive atoms\",\n",
       " 'When you take too much Acid',\n",
       " 'This is some NFT-able art.',\n",
       " 'This is so cool. Absolutely bookmarking to try it out later.',\n",
       " 'Awesome track too!',\n",
       " 'r/holofractal',\n",
       " 'I’m convinced Van Gogh’s self portrait was in the training/input.',\n",
       " 'Fucking legend.',\n",
       " \"Probably the coolest thing I've seen on this sub.\",\n",
       " 'I\\'m getting a \" Setting up TensorFlow plugin \"fused\\\\_bias\\\\_act.cu\": Failed! \" message before preparing audio and an Assertion error on the Hallucination stage, help??? lol',\n",
       " 'Is there a hacky way I could modify this to work with streaming audio from a place like spotify, or would it require a pretty big overhaul of the code? Does anyone know?',\n",
       " 'Any chance I could do this on Matlab?',\n",
       " 'If I send you a set of music can you add visual for me & add it to youtube?',\n",
       " 'Anyone getting a ModuleNotFound error? Cannot find dnnlib.',\n",
       " 'Cool, sell it to arty discos and festivals when lock down is gone.',\n",
       " 'Hey I made some videos but I am getting them down because of copyright on the music. I am not selling them or getting any money. Where can I legally show the work created?',\n",
       " 'u/thatdjgirl',\n",
       " 'Incredible. Absolutely incredible. Thank you',\n",
       " 'Is there any way to have it sample from 2 or more image libraries at once and have it mix them in the styles?\\n\\n&#x200B;\\n\\nI thought I might have had some success by adding an \"and\" but then it only chose one of the styles.\\n\\n&#x200B;\\n\\nWould be super cool to combine say abstract art with beetles :)',\n",
       " 'u/savemp4bot',\n",
       " 'This is satisfying to watch',\n",
       " 'Awesome! I think I broke my eyes. And my brain. #nextlevelshit',\n",
       " \"This has existed for a while now. You can look up Raspberry Lucid Sonic Dreams on YouTube and see that it's based on the same premise\",\n",
       " 'Have you found a way to make this 16:9?',\n",
       " 'now I can explain what a 3-gram mushroom trip looks like.',\n",
       " 'Give it your credit card and have it donate every time you stop working',\n",
       " 'Making that robot was procrastinating for sure as well',\n",
       " 'amazon would like to know your location',\n",
       " 'Here’s the development process and code: https://youtu.be/YPSazrEqlxo\\n\\nLmk your thoughts!',\n",
       " \"That is cool. However, procrastinating is a great thing to do. Most of my favorite papers and projects I've worked on come from me getting up from my desk and walking around the department looking for people to have coffee and random discussions so I don't have to work. So while maybe studying is important not to procrastinate, I have never found it detrimental in the long run.\",\n",
       " 'Does it give you a spanking?',\n",
       " 'Only issue is you can defeat the robot and still procrastinate',\n",
       " 'Please don’t give this to my employer.',\n",
       " 'This is amazing.',\n",
       " 'Building this setup myself for sure would be a great way to procrastinate on my thesis 🤔',\n",
       " 'How humans became slaves to their robot overlords: Genesis.',\n",
       " 'Nice work!',\n",
       " 'Amazing implementation',\n",
       " 'Nice work. Even though building that robot was definitely procrastination. 1',\n",
       " 'Bravissimo!',\n",
       " 'I need this right now',\n",
       " '[deleted]',\n",
       " 'This is very Dystopian tech.',\n",
       " 'Haha dang thats wild.',\n",
       " 'U/savevideobot',\n",
       " 'so what if you tape the pencil to the back of your phone?',\n",
       " 'Thanks for nothing. This will never be good. In any fashion or duty, unless you submit to it. What happens if you don’t submit?',\n",
       " \"Please don't...\",\n",
       " 'Kids getting a job at Amazon',\n",
       " \"That's awesome dude! I love it.\",\n",
       " 'Shock collar would have been more effective. But I guess this is still cheaper than a dominatrix.',\n",
       " 'What if You move away and sit on the bed with your phone?',\n",
       " 'Now you have to program it to prevent you from disabling it, and that kids is how Skynet started.',\n",
       " 'Making that was hardcore procrastination',\n",
       " 'Great way to give yourself tinnitus',\n",
       " 'There are TWO LIGHTS 😂',\n",
       " '*Amazon wants to know your location*',\n",
       " 'Now THIS is \"machine learning\"',\n",
       " 'Does anyone know how is the network detecting multiple objects at once? Can a network have variable output sizes for detecting more than one object?',\n",
       " 'That sound is so bad, it annoyed me with my headphones a meter away from me',\n",
       " \"Michael Reeves ain't got shit on you\",\n",
       " 'Thats an amazing accomplishment. 🌌',\n",
       " 'Lol 😂',\n",
       " 'Sal would be proud',\n",
       " 'That pen flip lmao',\n",
       " 'Keyboard?',\n",
       " 'Keyboard name? Also which pre-trained model did you use?',\n",
       " 'I think my procrastination is so strong I’d need pepper spray from the robot to truly scare me into submission',\n",
       " 'So what phones are those and is it using the camera?',\n",
       " 'At first I was reading punches...',\n",
       " 'Genious!',\n",
       " 'Pomodoro Technique, you deserve breaks',\n",
       " '[Posted on Reddit]',\n",
       " 'https://youtu.be/TTm7RzLKHIw\\n\\nYou should up your flash-bang game.',\n",
       " \"Every employer in the world drooling at the idea and wondering what slow frog boil method they'll use to get there.\",\n",
       " 'How’s the K8 Pro?',\n",
       " 'I was going to comment on this but I think I’ll just leave it till tomorrow.',\n",
       " 'Dope,\\n\\nAlthough I dunno how you flicked your pencil at ur monitor like that I could never.',\n",
       " 'this shit is so stupid, hide the phone off camera also pretend yo wobble the pen all the time so it think youre doing something, waste of time but im sure amazon would love this , they already stick the camera to their trucks and measure how often drivers are distracted and arent thinking about their work.What a shitty use of AI.Its supposed to help people and not help to punish people by non stop checking up on them.',\n",
       " 'the pencil flick on the monitor man',\n",
       " 'cool project',\n",
       " 'I read “punches me”. Kept waiting for the robot punch. Disappointed.',\n",
       " \"As long as toothbrush is in hand, you're doing good work, frand\",\n",
       " \"Is this the next thing companies are gonna put in to increase work?\\n\\nSir, this is great power and you have great responsibilities that come with. Don't sell this algorithm\",\n",
       " 'Song?',\n",
       " 'your brian needs breaks. it’s ok.',\n",
       " 'This was the push I needed to delete Candy Crush and Clash of Clans from my phone',\n",
       " \"This is a great idea! I'm going to implement at my office so my employees stay focused! /s\",\n",
       " 'AWESOME',\n",
       " \"Now imagine all the assignments you could have done instead of building this robot. Could we say it's procrastinating?\",\n",
       " ' lol plz dont show this code to the ccp',\n",
       " 'Great work, mate!',\n",
       " 'Who monitors if the robot is procrastinating?',\n",
       " 'This belongs in r/LateStageCapitalism',\n",
       " 'Me with ADHD:\\n\\n \"alright robot, you\\'re going to have to kill me\".',\n",
       " 'Make the robot *later*.',\n",
       " 'The pencil flip, so good.',\n",
       " 'Instead of the high pitched beeping it should play industry baby',\n",
       " 'shut up and take my money',\n",
       " \"Nice keyboard! What it's called?\",\n",
       " 'I think the best way to prevent wasting time is to turn off the phone)',\n",
       " 'The man created hell',\n",
       " 'You made the robot while procrastinating? XD',\n",
       " 'This is great. *Until schools have them.*',\n",
       " 'What DB tech are you using to communicate with detector?',\n",
       " \"I don't think negative reinforcement is a good way to deal with that...\",\n",
       " \"Let's see Paul Allen's procrastination punishment robot.\",\n",
       " 'I need this!!',\n",
       " 'I would simply turn the robot off, I am too devoted to procrastination. \\n\\nI am inevitable.',\n",
       " 'Name of the song?',\n",
       " 'Good idea but blinding your eyes will probably decrease your ability to focus',\n",
       " \"Nice. But this ain't a robot and all you have done is recognize the mobile phone using a camera, not recognize 'procrastination'. I guess this is the difference between what technical specs says and what a marketing guy says.\",\n",
       " 'Procrastobot',\n",
       " 'wow what a torture jail time equipment',\n",
       " 'My cat HATED that omg.',\n",
       " \"Didn't think we'd be automating doms anytime soon ...\",\n",
       " 'Bro can you share this app with us?',\n",
       " 'Cute but also scary! Modern-day equivalent of a whip.',\n",
       " 'Studying is a massive waste of time. It is glorifying the special human characteristic of being terrible at retaining information. The simple solution would be to manufacture a memory retention system within your brain that didn’t totally suck and didn’t require you to study in the first place. Should be able to simply copy the information into your head.',\n",
       " 'Provide a link to the original paper, as well as code used.',\n",
       " '1. Girl with a Pearl Earring (by Johannes Vermeer)\\n2. Pavel Alexandrovich Stroganov – *Russian commander* (thx /u/j4_james)\\n3. Leonardo DaVinci – *Painter and Polymath*\\n4. Charles Darwin – *Evolution Theory*\\n5. Mona Lisa (by Leonardo DaVinci)\\n6. Ludwig van Beethoven – *Composer*\\n7. Thomas Jefferson *– 3rd US president* (thx /u/j4_james)\\n8. Charles Willson Peale – *American painter* (thx /u/j4_james)\\n9. Pyotr Andreyevich Shuvalov – *Russian Statesman* (thx /u/NotNotWrongUsually)\\n10. George Washington – *1st US President*\\n11. Baron René Hyacinthe Holstein (thx /u/j4_james)\\n12. William Man Godschall (by John Russell)\\n13. Antoine-Jean Gros – *French painter* (thx /u/j4_james)\\n14. Louis XV – *King of France*\\n15. Jean-Jacques Rousseau – *Genevan Philosopher*\\n16. Isaac Newton – *Gravity Theory*\\n17. William Shakespeare – *English Playwright*\\n18. John Law – *Scottish Economist* (thx /u/tempacc_2020_2)\\n19. Abraham Velters (thx /u/j4_james)\\n20. Galileo Galilei – *Astronomer and Polymath* (thx /u/Dedexy)\\n21. Carl Friedrich Gauß – *German Mathematician*\\n22. Pretty lady in brown hat (by Nicolas Largillierre) (thx /u/j4_james)\\n23. Louis Antoine Léon de\\xa0Saint-Just – *French legislator/revolutionary* (thx /u/fatlewis)\\n24. Alexandre Michaud – *Russian General* (thx /u/runic7_)\\n25. Stendhal – *French Writer*',\n",
       " 'Well that’s unsettling',\n",
       " 'Thanks, Bella Porch.',\n",
       " '[deleted]',\n",
       " \"What's up with all those Ai projects using bella porch as their sample, I've seen two today already\",\n",
       " 'What does \"First order model\" mean though?',\n",
       " 'It looks like a zoom party?',\n",
       " 'I post all my experiments on my [Instagram page](https://www.instagram.com/p/CFQZ4YhHOC6/?igshid=v4v0um9hxt5f) feel free to give a look',\n",
       " 'Is it weird I knew the song without clicking on the video',\n",
       " 'I laughed more than I should have to this one XD',\n",
       " 'What’s this song called?',\n",
       " \"When DJ Weasely's dropping bangers in the common room\",\n",
       " 'Without sound I feel like I am in the Hogwarts.',\n",
       " 'Nice! The Mona Lisa looks like the guy who sells me my coffee every morning.',\n",
       " \"Mona Lisa's got some funky jowl swinging, there.\",\n",
       " 'gonna take shrooms then revisit this.',\n",
       " 'It a really good job 👍🏻',\n",
       " 'Louis XV seems to be having the most fun in my assessment.',\n",
       " 'What video did you use for the motion capture?',\n",
       " 'That is so dope',\n",
       " \"I can't stop watching this\",\n",
       " 'u/VRedditDownloader',\n",
       " 'whoa',\n",
       " 'Very nice, have to say I caught myself bobbing my head to the music too... followed you on Instagram. Thanks for sharing.',\n",
       " \"I....\\n\\nI'm ok with this.\",\n",
       " 'r/TIHI\\n\\n...I actually don’t hate it, but it creeps me out in a good way',\n",
       " 'Title of the song?',\n",
       " 'the indian headbobs!',\n",
       " 'Why tf is this visually satisfying',\n",
       " 'Stunning.',\n",
       " 'the girl with the pearl earring looks like a fish when she turns her head to the right at the end of the video',\n",
       " \"Zoomin' through history while dropping some bass.\",\n",
       " 'Absolute gem! Forget github, someone add this to tik tok stat ha ha',\n",
       " 'This is what tripping is like :D',\n",
       " 'Baka mitai v2 incoming',\n",
       " 'u/VRedditDownloader',\n",
       " 'u/VRedditDownloader',\n",
       " 'Potter Tech',\n",
       " 'I know exactly which video it is and it should definitely instead be the m to the b zoom call with the dog',\n",
       " 'Okaay...',\n",
       " 'Good job and nice to see all these people \"dancing together\".',\n",
       " 'I find this highly entertaining.',\n",
       " 'This need to be looped.',\n",
       " \"beethoven only grimaces and scowls, which is peculiarly funny.  washington looks like he's having some peculiar facial problems, like maybe he ate some ergot\",\n",
       " 'Have you ever experimented with pixel art style transfer? I have never seen something like that before and just realized it could be dope',\n",
       " 'That guy in the bottom right looks freaky real',\n",
       " 'Thanks I hate it',\n",
       " 'This looks like the live paintings ftom harry potter.',\n",
       " 'The next step must be the harry potter newspapers.',\n",
       " '\"Hip hop a hippity hop\" 🎵🎵',\n",
       " \"Bro could you do something like this with one of my cousins paintings? I think it'd be really fun to surprise her with it? xD\",\n",
       " 'The model is absolutely fantastic but plz for the love of god people have to stop using this song',\n",
       " '[deleted]',\n",
       " 'D O P E']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the answer may vary 693 for r/machinelearning\n",
    "top_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['re-animator',\n",
       " 'Give it your credit card and have it donate every time you stop working',\n",
       " 'That is creepy af']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "[random.choice(top_comments) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> <summary>Some of the comments from `r/machinelearning` subreddit are:</summary>\n",
    "\n",
    "    ['Awesome visualisation',\n",
    "    'Similar to a stack or connected neurons.',\n",
    "    'Will this Turing pass the Turing Test?']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 5. Extract Top Level Comment from Subreddit `TSLA`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Write your code to extract top level comments from the top 10 topics of a time period, e.g., year, from subreddit `TSLA` and store them in a list `top_comments_tsla`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up Vote if you would like to see a 1for 5 stock split?\n",
      "Raise your hands if you stayed long and didn’t de-risk on Tesla because of your research and faith in the actual company.\n",
      "Vote up for a 10 for 1 stock split (at 1500/share before split)!\n",
      "I’m a small fry, but happy to say I’ve just passed Half a share of TSLA! Hoping to get to a full share by year end.\n",
      "Record Deliveries in Q4 2021\n",
      "All in on TSLA\n",
      "Pepsi buying Tesla trucks\n",
      "Tesla To 1.2k and Beyond\n",
      "Bought on the dip today. Who’s with me?\n",
      "Congrats my fellow longs\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit('TSLA')\n",
    "\n",
    "top_10 = subreddit.top(time_filter=\"year\",limit=10)\n",
    "for submission in top_10:\n",
    "    print(submission.title)\n",
    "    \n",
    "#%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# Initialize an empty list for top_comments\n",
    "top_comments_tsla = []\n",
    "\n",
    "for submission in subreddit.top(limit=10):\n",
    "    for top_level_comment in submission.comments:\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        top_comments_tsla.append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_comments_tsla) # Expected: 174 for r/machinelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Have you ever talked with Elon? Could say few words about him? Thanks',\n",
       " 'Hold then.\\nNever sell.',\n",
       " 'That stupidity of Bitcoin buying spooked a lot of investors. Now Musk tied his and every investors ass to BTC. It was a Bad Move to go out buying Criptos and blowing dog whistles at an idiotic asset like Dogecoin. That conveys non sereousness on part of Musk. On Wall Street Perception is Everything. Now we are Bleeding.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "[random.choice(top_comments_tsla) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Some of the comments from `r/TSLA` subreddit:</summary>\n",
    "\n",
    "    ['I bought puts',\n",
    "    '100%',\n",
    "    'Yes. And I’m bag holding 1200 calls for Friday and am close to throwing myself out the window']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task III: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us analyze the sentiment of comments scraped from `r/TSLA` using a pre-trained HuggingFace model to make the inference. Take a [Quick tour](https://huggingface.co/docs/transformers/quicktour). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Import `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2. Create a Pipeline to Perform Task \"sentiment-analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "sentiment_model =  pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Get one comment from list `top_comments_tsla` from Task II - 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comment = random.choice(top_comments_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"didn't sell shares today\\n\\nauto executed 2 trailing stop loss options with 87% profit. fuck yeah!\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example comment is: `'Bury Burry!!!!!'`. Print out what you get. For reproducibility, use the same comment in the next step; consider setting a seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Make Inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8111267685890198}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = sentiment_model(comment)\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the type of the output `sentiment`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "YOUR ANSWER HERE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comment: didn't sell shares today\n",
      "\n",
      "auto executed 2 trailing stop loss options with 87% profit. fuck yeah!\n",
      "Predicted Label is NEGATIVE and the score is 0.811\n"
     ]
    }
   ],
   "source": [
    "print(f'The comment: {comment}')\n",
    "print(f'Predicted Label is {sentiment[0][\"label\"]} and the score is {sentiment[0][\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example comment, the output is:\n",
    "\n",
    "    The comment: Bury Burry!!!!!\n",
    "    Predicted Label is NEGATIVE and the score is 0.989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task IV: Put All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull all the piece together, create a simple script that does \n",
    "\n",
    "- get the subreddit\n",
    "- get comments from the top posts for given subreddit\n",
    "- run sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you complete the code, running the following block writes the code into a new Python script and saves it as `top_tlsa_comment_sentiment.py` under the same directory with the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting top_tlsa_comment_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_tlsa_comment_sentiment.py\n",
    "\n",
    "import redditsecrets\n",
    "import random\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "from praw import Reddit\n",
    "from praw.models.reddit.subreddit import Subreddit\n",
    "from praw.models import MoreComments\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def get_subreddit(display_name:str) -> Subreddit:\n",
    "    \"\"\"Get subreddit object from display name\n",
    "\n",
    "    Args:\n",
    "        display_name (str): [description]\n",
    "\n",
    "    Returns:\n",
    "        Subreddit: [description]\n",
    "    \"\"\"\n",
    "    reddit = Reddit(\n",
    "        client_id=redditsecrets.REDDIT_API_CLIENT_ID,        \n",
    "        client_secret=redditsecrets.REDDIT_API_CLIENT_SECRET,\n",
    "        user_agent=redditsecrets.REDDIT_API_USER_AGENT\n",
    "        )\n",
    "    \n",
    "    subreddit = reddit.subreddit('TSLA')\n",
    "    \n",
    "    return subreddit\n",
    "\n",
    "def get_comments(subreddit:Subreddit, limit:int=3) -> List[str]:\n",
    "    \"\"\" Get comments from subreddit\n",
    "\n",
    "    Args:\n",
    "        subreddit (Subreddit): [description]\n",
    "        limit (int, optional): [description]. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of comments\n",
    "    \"\"\"\n",
    "    top_comments = []\n",
    "    for submission in subreddit.top(limit=limit):\n",
    "        for top_level_comment in submission.comments:\n",
    "            if isinstance(top_level_comment, MoreComments):\n",
    "                continue\n",
    "            top_comments.append(top_level_comment.body)\n",
    "    return top_comments\n",
    "\n",
    "def run_sentiment_analysis(comment:str) -> Dict:\n",
    "    \"\"\"Run sentiment analysis on comment using default distilbert model\n",
    "    \n",
    "    Args:\n",
    "        comment (str): [description]\n",
    "        \n",
    "    Returns:\n",
    "        str: Sentiment analysis result\n",
    "    \"\"\"\n",
    "    sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "    sentiment = sentiment_model(comment)\n",
    "    return sentiment[0]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    subreddit = get_subreddit(display_name='TSLA') \n",
    "    comments = get_comments(subreddit)\n",
    "    comment = random.choice(comments) \n",
    "    sentiment = run_sentiment_analysis(comment)\n",
    "    \n",
    "    print(f'The comment: {comment}')\n",
    "    print(f'Predicted Label is {sentiment[\"label\"]} and the score is {sentiment[\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following block to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
      "The comment: [removed]\n",
      "Predicted Label is NEGATIVE and the score is 0.993\n"
     ]
    }
   ],
   "source": [
    "!python top_tlsa_comment_sentiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> Expected output:</summary>\n",
    "\n",
    "    No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "    The comment: When is DOGE flying\n",
    "    Predicted Label is POSITIVE and the score is 0.689\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70e5a9886b02a227d3c83e17263e3a28d12f842d6950be488144931078452c0e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
